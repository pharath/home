<!DOCTYPE html>
<html data-rh="lang" lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><script type="text/javascript" async="" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-Cx10SI4nRyIf/4CfTL8bj2s8I5ccz18HDscUBxSzsbe1SPnhchceoHtCw2m0nc/h"></script><script async="" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/branch-latest.js"></script><script async="" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/analytics.js"></script><script defer="defer" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/16180790160.js"></script><title>Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming | by James Dellinger | Towards Data Science</title><meta data-rh="true" charset="utf-8"><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2019-04-04T17:08:37.064Z"><meta data-rh="true" name="title" content="Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming | by James Dellinger | Towards Data Science"><meta data-rh="true" property="og:title" content="Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming"><meta data-rh="true" property="twitter:title" content="Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/954fb9b47c79"><meta data-rh="true" property="al:android:url" content="medium://p/954fb9b47c79"><meta data-rh="true" property="al:ios:url" content="medium://p/954fb9b47c79"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="I’d like to invite you to join me on an exploration through different approaches to initializing layer weights in neural networks. Step-by-step, through various short experiments and thought…"><meta data-rh="true" property="og:description" content="Exploring the evolution of initializing layer weights in neural networks: from old-school to Xavier, and arriving finally at Kaiming init."><meta data-rh="true" property="twitter:description" content="Exploring the evolution of initializing layer weights in neural networks: from old-school to Xavier, and arriving finally at Kaiming init."><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*AcZIzXFAJm_ZafRKleF_0g.png"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*AcZIzXFAJm_ZafRKleF_0g.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://medium.com/@jamesdell"><meta data-rh="true" name="twitter:creator" content="@jamrdell"><meta data-rh="true" name="author" content="James Dellinger"><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="11 min read"><meta data-rh="true" name="parsely-post-id" content="954fb9b47c79"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@jamesdell"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/954fb9b47c79"><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="608" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-moz-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-webkit-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-moz-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-webkit-keyframes k3{0%{transform:translateX(-1%)}20%{transform:translateX(1%)}40%{transform:translateX(-1%)}60%{transform:translateX(1%)}80%{transform:translateX(-1%)}100%{transform:translateX(1%)}}@-moz-keyframes k3{0%{transform:translateX(-1%)}20%{transform:translateX(1%)}40%{transform:translateX(-1%)}60%{transform:translateX(1%)}80%{transform:translateX(-1%)}100%{transform:translateX(1%)}}@keyframes k3{0%{transform:translateX(-1%)}20%{transform:translateX(1%)}40%{transform:translateX(-1%)}60%{transform:translateX(1%)}80%{transform:translateX(-1%)}100%{transform:translateX(1%)}}@-webkit-keyframes k4{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k4{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k4{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:25px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{margin-bottom:36px}.v{width:100%}.w{overflow-x:scroll}.x{white-space:nowrap}.y{scrollbar-width:none}.z{-ms-overflow-style:none}.ab::-webkit-scrollbar{display:none}.ac{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.ae{min-height:184px}.ah{flex-direction:column}.ai{background-color:#355876}.aj{display:none}.al{border-bottom:none}.am{position:relative}.an{z-index:500}.at{max-width:1192px}.au{min-width:0}.av{height:62px}.aw{flex-direction:row}.ax{flex:1 0 auto}.ay{visibility:hidden}.az{margin-right:16px}.ba{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bb{font-size:14px}.bc{line-height:20px}.bd{color:rgba(233, 241, 250, 1)}.be{padding:7px 16px 9px}.bf{background:0}.bg{fill:rgba(233, 241, 250, 1)}.bh{border-color:rgba(215, 226, 238, 1)}.bm:disabled{cursor:inherit}.bn:disabled{opacity:0.3}.bo:disabled:hover{color:rgba(233, 241, 250, 1)}.bp:disabled:hover{fill:rgba(233, 241, 250, 1)}.bq:disabled:hover{border-color:rgba(215, 226, 238, 1)}.br{border-radius:4px}.bs{border-width:1px}.bt{border-style:solid}.bu{box-sizing:border-box}.bv{display:inline-block}.bw{text-decoration:none}.bx{margin-left:0px}.by{color:rgba(197, 210, 225, 1)}.bz{font-size:inherit}.ca{border:inherit}.cb{font-family:inherit}.cc{letter-spacing:inherit}.cd{font-weight:inherit}.ce{padding:0}.cf{margin:0}.cg:disabled{cursor:default}.ch:disabled{color:rgba(163, 208, 162, 0.5)}.ci:disabled{fill:rgba(163, 208, 162, 0.5)}.cj{min-height:115px}.ck{justify-content:space-between}.cq{align-items:flex-start}.cr{margin-bottom:0px}.cs{margin-top:-32px}.ct{flex-wrap:wrap}.cw{margin-top:32px}.cx{margin-right:24px}.cz{height:35px}.da{width:112px}.db{flex:0 0 auto}.dc{justify-self:flex-end}.dd{margin-bottom:-3px}.de{margin-left:14px}.df{margin-top:-3px}.dg{fill:rgba(251, 255, 255, 1)}.dh{padding-top:1px}.di{height:70px}.dk{font-size:16px}.dl{line-height:24px}.dm:before{margin-bottom:-10px}.dn:before{content:""}.do:before{display:table}.dp:before{border-collapse:collapse}.dq:after{margin-top:-6px}.dr:after{content:""}.ds:after{display:table}.dt:after{border-collapse:collapse}.du{color:rgba(117, 117, 117, 1)}.dv{margin-right:32px}.dw{margin-bottom:-16px}.dx{margin-top:-14px}.dy{color:rgba(255, 255, 255, 1)}.dz{fill:rgba(255, 255, 255, 1)}.ea{background:rgba(102, 138, 170, 1)}.eb{border-color:rgba(102, 138, 170, 1)}.ee:disabled:hover{background:rgba(102, 138, 170, 1)}.ef:disabled:hover{border-color:rgba(102, 138, 170, 1)}.eg{margin-right:12px}.eh{display:inline-flex}.ei{color:inherit}.ej{fill:inherit}.em:disabled{color:rgba(117, 117, 117, 1)}.en:disabled{fill:rgba(117, 117, 117, 1)}.eo{margin-left:12px}.ep{margin:0 12px}.eq{position:absolute}.er{right:24px}.es{margin:0px}.et{border:0px}.eu{padding:0px}.ev{cursor:pointer}.ew{stroke:rgba(117, 117, 117, 1)}.ez{border-top:none}.fa{left:0}.fb{opacity:0}.fc{position:fixed}.fd{right:0}.fe{top:0}.fg{height:60px}.fj{color:rgba(102, 138, 170, 1)}.fk{fill:rgba(102, 138, 170, 1)}.fn:disabled:hover{color:rgba(102, 138, 170, 1)}.fo:disabled:hover{fill:rgba(102, 138, 170, 1)}.fp{margin-left:16px}.fq{padding-left:24px}.fr{padding-right:24px}.fs{margin-left:auto}.ft{margin-right:auto}.fu{max-width:728px}.fv{top:calc(100vh + 100px)}.fw{bottom:calc(100vh + 100px)}.fx{width:10px}.fy{pointer-events:none}.fz{word-break:break-word}.ga{word-wrap:break-word}.gb:after{display:block}.gc:after{clear:both}.gd{max-width:680px}.ge{line-height:1.23}.gf{letter-spacing:0}.gg{font-style:normal}.gh{font-weight:700}.hc{margin-bottom:-0.27em}.hd{color:rgba(41, 41, 41, 1)}.hh{border-radius:50%}.hi{height:28px}.hj{width:28px}.hk{margin:0 4px}.hl{margin:0 7px}.hm{align-items:flex-end}.hv{padding-right:6px}.hw{margin-right:8px}.hx{fill:rgba(117, 117, 117, 1)}.hy{margin-right:-6px}.hz{line-height:1.58}.ia{letter-spacing:-0.004em}.ib{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.ir{margin-top:24px}.is{margin-bottom:-0.46em}.iy{text-decoration:underline}.iz{line-height:1.18}.ja{letter-spacing:-0.022em}.jb{font-weight:500}.jw{margin-bottom:-0.31em}.kc{max-width:1400px}.ki{clear:both}.kk{cursor:zoom-in}.kl{z-index:auto}.kn{transition:opacity 100ms 400ms}.ko{height:100%}.kp{overflow:hidden}.kq{will-change:transform}.kr{transform:translateZ(0)}.ks{margin:auto}.kt{background-color:rgba(242, 242, 242, 1)}.ku{padding-bottom:6.428571428571429%}.kv{height:0}.kw{filter:blur(20px)}.kx{transform:scale(1.1)}.ky{visibility:visible}.kz{font-style:italic}.la{padding-bottom:19.285714285714285%}.lb{padding-bottom:28.428571428571427%}.lc{padding-bottom:25.714285714285715%}.ld{padding-bottom:15.142857142857142%}.le{padding:20px}.lf{background:rgba(242, 242, 242, 1)}.lg{overflow-x:auto}.lh{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.li{margin-top:-0.09em}.lj{margin-bottom:-0.09em}.lk{white-space:pre-wrap}.ll{padding-bottom:43.99999999999999%}.lm{padding-bottom:31.71428571428571%}.ln{padding-bottom:44.14285714285714%}.lo{max-width:371px}.lp{padding-bottom:71.1590296495957%}.lq{margin-top:10px}.lr{text-align:center}.lu{padding-bottom:33.142857142857146%}.lv{padding-bottom:23.571428571428573%}.lw{padding-bottom:16.142857142857142%}.lx{padding-bottom:33.85714285714286%}.ly{padding-bottom:34.285714285714285%}.lz{padding-bottom:32.14285714285714%}.ma{max-width:357px}.mb{padding-bottom:77.87114845938375%}.mc{padding-bottom:39.42857142857142%}.md{padding-bottom:10.428571428571429%}.me{padding-bottom:31.857142857142854%}.mf{list-style-type:decimal}.mg{margin-left:30px}.mh{padding-left:0px}.mn{padding-bottom:36.142857142857146%}.mo{padding-bottom:26.142857142857146%}.mp{padding-bottom:57.85714285714286%}.mq{will-change:opacity}.mr{width:188px}.ms{left:50%}.mt{transform:translateX(406px)}.mu{top:calc(65px + 54px + 14px)}.mx{top:159px}.mz{width:131px}.na{padding-bottom:28px}.nb{border-bottom:1px solid rgba(230, 230, 230, 1)}.nc{font-size:12px}.nd{line-height:16px}.ne{letter-spacing:0.083em}.nf{text-transform:uppercase}.ng{padding-bottom:5px}.nh{padding-top:5px}.ni{padding-top:14px}.nj{padding-top:28px}.nk{margin-bottom:19px}.nl{margin-left:-3px}.nr{outline:0}.ns{border:0}.nt{user-select:none}.nu> svg{pointer-events:none}.nw{-webkit-user-select:none}.og button{text-align:left}.oh{opacity:0.4}.oi{cursor:not-allowed}.oj{padding-right:9px}.os{margin-top:40px}.ot{border-top:3px solid rgba(102, 138, 170, 1)}.ou{padding:32px 32px 26px 32px}.ov{margin-top:8px}.ow{margin-bottom:25px}.ox{background-color:rgba(250, 250, 250, 1)}.oz{padding-bottom:0px}.pa{padding-top:4px}.pb{font-size:13px}.pc{padding-bottom:10px}.pd{padding-top:8px}.po{justify-content:flex-start}.pp{display:inline}.pq{height:56px}.pt{margin-top:}.pv{background:transparent}.pw{border:none}.px{outline:none}.py::-webkit-inner-spin-button{-webkit-appearance:none}.pz::-webkit-inner-spin-button{-moz-appearance:none}.qa::-webkit-inner-spin-button{appearance:none}.qb::-webkit-inner-spin-button{margin:0}.qc::-webkit-outer-spin-button{-webkit-appearance:none}.qd::-webkit-outer-spin-button{-moz-appearance:none}.qe::-webkit-outer-spin-button{appearance:none}.qf::-webkit-outer-spin-button{margin:0}.qg{width:375px}.qh{font:inherit}.qi{padding-left:auto}.qj{padding-right:auto}.qk{text-align:start}.ql::placeholder{color:rgba(117, 117, 117, 1)}.qm{padding-bottom:1px}.qn{border-bottom:1px solid rgba(168, 168, 168, 1)}.qo{margin-bottom:auto}.qp{margin-left:15px}.qr{padding:7px 20px 9px}.qs{padding-top:}.qt{font-size:11px}.qu{margin-bottom:15px}.qv{margin-top:5px}.qw{padding-bottom:25px}.qx{margin-top:25px}.qy{max-width:155px}.rc{top:1px}.rq{margin-left:-1px}.rr{margin-left:-4px}.rz{padding-right:8px}.sa{padding-bottom:40px}.sb{list-style-type:none}.sc{margin-bottom:8px}.sd{line-height:22px}.se{border-radius:3px}.sf{padding:5px 10px}.sg{padding-bottom:4px}.sh{padding-top:32px}.ss{text-overflow:ellipsis}.st{display:-webkit-box}.su{-webkit-line-clamp:1}.sv{-webkit-box-orient:vertical}.sx{padding-right:168px}.sy{padding-top:25px}.te{max-width:100%}.tf{margin-bottom:96px}.tg{background:rgba(255, 255, 255, 1)}.th{margin-bottom:40px}.ti{padding-bottom:16px}.tj{margin-bottom:24px}.uv{flex-grow:0}.uw{padding-bottom:24px}.ux{max-width:500px}.uy{flex:0 1 auto}.vc{padding-bottom:8px}.vk{padding-bottom:100%}.vv{padding:32px 0}.vw{background-color:rgba(0, 0, 0, 0.9)}.wa:disabled{color:rgba(255, 255, 255, 0.7)}.wb:disabled{fill:rgba(255, 255, 255, 0.7)}.wc{height:22px}.wd{color:rgba(255, 255, 255, 0.7)}.we{width:200px}.wg{color:rgba(255, 255, 255, 0.98)}.bi:hover{color:rgba(251, 255, 255, 1)}.bj:hover{fill:rgba(251, 255, 255, 1)}.bk:hover{border-color:rgba(251, 255, 255, 1)}.bl:hover{cursor:pointer}.ec:hover{background:rgba(90, 118, 144, 1)}.ed:hover{border-color:rgba(90, 118, 144, 1)}.ek:hover{color:rgba(25, 25, 25, 1)}.el:hover{fill:rgba(25, 25, 25, 1)}.fl:hover{color:rgba(90, 118, 144, 1)}.fm:hover{fill:rgba(90, 118, 144, 1)}.ny:hover{fill:rgba(117, 117, 117, 1)}.vh:hover{text-decoration:underline}.vy:hover{color:rgba(255, 255, 255, 0.99)}.vz:hover{fill:rgba(255, 255, 255, 0.99)}.km:focus{transform:scale(1.01)}.nx:focus{fill:rgba(117, 117, 117, 1)}.nv:active{border-style:none}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.as{margin:0 64px}.gy{font-size:46px}.gz{margin-top:0.6em}.ha{line-height:56px}.hb{letter-spacing:-0.011em}.ht{margin-left:30px}.io{font-size:21px}.ip{line-height:32px}.iq{letter-spacing:-0.003em}.ix{margin-top:2em}.js{font-size:22px}.jt{margin-top:1.72em}.ju{line-height:28px}.jv{letter-spacing:0}.kb{margin-top:0.86em}.kh{margin-top:56px}.mm{margin-top:1.05em}.nq{margin-right:5px}.of{margin-top:5px}.or{padding-left:6px}.pm{font-size:16px}.pn{line-height:24px}.re{display:inline-block}.rj{margin-left:7px}.rk{margin-top:8px}.rp{width:25px}.rx{padding-left:7px}.ry{top:3px}.sq{font-size:20px}.sr{max-height:24px}.td{margin:0}.ty{width:calc(100% + 32px)}.tz{margin-left:-16px}.ua{margin-right:-16px}.ur{padding-left:16px}.us{padding-right:16px}.ut{flex-basis:25%}.uu{max-width:25%}.vf{line-height:20px}.vt{min-width:70px}.vu{min-height:70px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.hs{margin-left:30px}.ls{margin-left:auto}.lt{text-align:center}.np{margin-right:5px}.oe{margin-top:5px}.oq{padding-left:6px}.rd{display:inline-block}.rh{margin-left:7px}.ri{margin-top:8px}.ro{width:25px}.rv{padding-left:7px}.rw{top:3px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.hr{margin-left:30px}.no{margin-right:5px}.od{margin-top:5px}.oo{padding-left:6px}.op{top:3px}.rb{display:inline-block}.rf{margin-left:7px}.rg{margin-top:8px}.rn{width:15px}.ru{padding-left:3px}.vb{margin-right:16px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.u{margin-bottom:20px}.af{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.ag{min-height:230px}.ak{display:block}.cl{min-height:98px}.cm{display:flex}.cn{align-items:flex-start}.co{flex-direction:column}.cp{justify-content:flex-end}.cu{margin-bottom:28px}.cv{margin-top:0px}.cy{margin-top:28px}.dj{margin:0}.ex{border-top:1px solid rgba(230, 230, 230, 1)}.ey{border-bottom:1px solid rgba(230, 230, 230, 1)}.fh{align-items:center}.fi{flex:1 0 auto}.hf{margin-top:32px}.hg{flex-direction:column-reverse}.hp{margin-bottom:30px}.hq{margin-left:0px}.nn{margin-left:8px}.ob{margin-top:2px}.oc{margin-right:8px}.om{padding-left:6px}.on{top:3px}.oy{padding:24px 24px 28px 24px}.pr{padding-top:16px}.ps{height:130px}.pu{margin-top:0}.qq{margin-top:15px}.ra{display:inline-block}.rm{width:15px}.rt{padding-left:3px}.tk{padding-bottom:12px}.tl{margin-top:16px}.va{margin-right:16px}.vi{margin-left:16px}.vj{margin-right:0px}.vx{padding:32px 0}.wf{width:140px}.wh{margin-bottom:16px}.wi{margin-top:30px}.wj{width:100%}.wk{flex-direction:row}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.ao{margin:0 24px}.gi{font-size:32px}.gj{margin-top:0.64em}.gk{line-height:40px}.gl{letter-spacing:-0.016em}.he{margin-top:32px}.hn{margin-bottom:30px}.ho{margin-left:0px}.ic{font-size:18px}.id{line-height:28px}.ie{letter-spacing:-0.003em}.it{margin-top:1.56em}.jc{font-size:20px}.jd{margin-top:1.23em}.je{line-height:24px}.jf{letter-spacing:0}.jx{margin-top:0.67em}.kd{margin-top:40px}.mi{margin-top:1.34em}.nm{margin-left:8px}.nz{margin-top:2px}.oa{margin-right:8px}.ok{padding-left:6px}.ol{top:3px}.pe{font-size:14px}.pf{line-height:20px}.qz{display:inline-block}.rl{width:15px}.rs{padding-left:3px}.si{font-size:16px}.sj{max-height:20px}.sz{margin:0}.tm{width:calc(100% + 24px)}.tn{margin-left:-12px}.to{margin-right:-12px}.ub{padding-left:12px}.uc{padding-right:12px}.ud{flex-basis:100%}.ue{max-width:100%}.uz{margin-right:16px}.vg{margin-bottom:0px}.vl{min-width:48px}.vm{min-height:48px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ar{margin:0 64px}.gu{font-size:46px}.gv{margin-top:0.6em}.gw{line-height:56px}.gx{letter-spacing:-0.011em}.il{font-size:21px}.im{line-height:32px}.in{letter-spacing:-0.003em}.iw{margin-top:2em}.jo{font-size:22px}.jp{margin-top:1.72em}.jq{line-height:28px}.jr{letter-spacing:0}.ka{margin-top:0.86em}.kg{margin-top:56px}.ml{margin-top:1.05em}.pk{font-size:16px}.pl{line-height:24px}.so{font-size:20px}.sp{max-height:24px}.tc{margin:0}.tv{width:calc(100% + 32px)}.tw{margin-left:-16px}.tx{margin-right:-16px}.un{padding-left:16px}.uo{padding-right:16px}.up{flex-basis:25%}.uq{max-width:25%}.ve{line-height:20px}.vr{min-width:70px}.vs{min-height:70px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.aq{margin:0 48px}.gq{font-size:46px}.gr{margin-top:0.6em}.gs{line-height:56px}.gt{letter-spacing:-0.011em}.ii{font-size:21px}.ij{line-height:32px}.ik{letter-spacing:-0.003em}.iv{margin-top:2em}.jk{font-size:22px}.jl{margin-top:1.72em}.jm{line-height:28px}.jn{letter-spacing:0}.jz{margin-top:0.86em}.kf{margin-top:56px}.mk{margin-top:1.05em}.pi{font-size:16px}.pj{line-height:24px}.sm{font-size:20px}.sn{max-height:24px}.tb{margin:0}.ts{width:calc(100% + 28px)}.tt{margin-left:-14px}.tu{margin-right:-14px}.uj{padding-left:14px}.uk{padding-right:14px}.ul{flex-basis:50%}.um{max-width:50%}.vd{line-height:20px}.vp{min-width:48px}.vq{min-height:48px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ap{margin:0 24px}.gm{font-size:32px}.gn{margin-top:0.64em}.go{line-height:40px}.gp{letter-spacing:-0.016em}.if{font-size:18px}.ig{line-height:28px}.ih{letter-spacing:-0.003em}.iu{margin-top:1.56em}.jg{font-size:20px}.jh{margin-top:1.23em}.ji{line-height:24px}.jj{letter-spacing:0}.jy{margin-top:0.67em}.ke{margin-top:40px}.mj{margin-top:1.34em}.pg{font-size:14px}.ph{line-height:20px}.sk{font-size:16px}.sl{max-height:20px}.ta{margin:0}.tp{width:calc(100% + 24px)}.tq{margin-left:-12px}.tr{margin-right:-12px}.uf{padding-left:12px}.ug{padding-right:12px}.uh{flex-basis:100%}.ui{max-width:100%}.vn{min-width:48px}.vo{min-height:48px}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="print">.hu{display:none}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.ff{animation:k2 .2s ease-in-out both}.kj{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.mv{transition:opacity 200ms}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (max-width: 1230px)">.mw{display:none}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="all and (max-width: 1198px)">.my{display:none}</style><style type="text/css" data-fela-rehydration="608" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.sw{max-height:none}</style><link rel="icon" href="https://miro.medium.com/fit/c/128/128/1*ChFMdf--f5jbm-AYv6VdYA@2x.png" data-rh="true"><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*AcZIzXFAJm_ZafRKleF_0g.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79","dateCreated":"2019-04-03T08:43:45.838Z","datePublished":"2019-04-03T08:43:45.838Z","dateModified":"2019-04-04T17:08:37.166Z","headline":"Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming","name":"Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming","description":"I’d like to invite you to join me on an exploration through different approaches to initializing layer weights in neural networks. Step-by-step, through various short experiments and thought…","identifier":"954fb9b47c79","keywords":["Lite:true","Tag:Deep Learning","Tag:Neural Networks","Tag:Weight Initialization","Tag:Towards Data Science","Publication:towards-data-science","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:3"],"author":{"@type":"Person","name":"James Dellinger","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@jamesdell"},"creator":["James Dellinger"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F165\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79"}</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><div class="s"><div class="t s u"><div class="ac ae s af ag"><div class="n ah ai"><div class="aj ak"><div class="al s am an"><div class="n p"><div class="ao ap aq ar as at au v"><div class="av n o"><div class="n o aw ax"><div class="ky" id="lo-meta-header-sign-up-button"><div class="az s"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_page-----954fb9b47c79---------------------nav_reg-----------" class="ba b bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq br bs bt bu bv bw" rel="noopener">Get started</a></span></div></div><div class="ky" id="lo-ShowPostUnderCollection-navbar-open-in-app-button"><div class="bx aj ak"><span class="ba b bb bc by"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F954fb9b47c79&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderCollection&amp;~stage=mobileNavBar&amp;source=post_page-----954fb9b47c79--------------------------------" class="bd bg bz ca cb cc cd ce cf bl bi bj cg ch ci" rel="noopener nofollow">Open in app</a></span></div></div></div><a href="https://medium.com/?source=post_page-----954fb9b47c79--------------------------------" aria-label="Homepage" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="q bg"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div><div class="n p"><div class="ao ap aq ar as at au v"><div class="cj n o aw ck cl cm cn co cp"><div class="v n cq ck"><div class="n v"><div class="cr cs v n o aw ct cu cv cm cn co"><div class="cw cx s cy"><a aria-label="Publication Homepage" rel="noopener" href="https://towardsdatascience.com/?source=post_page-----954fb9b47c79--------------------------------"><div class="cz da s"><img alt="Towards Data Science" class="" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AGyTPCaRzVqL77kFwUwHKg.png" width="112" height="35"></div></a></div></div></div><div class="n o db dc an g"><div class="ky" id="lo-meta-header-sign-in-link"><h4 class="ba b bb bc by"><span><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_page-----954fb9b47c79---------------------nav_reg-----------" class="bd bg bz ca cb cc cd ce cf bl bi bj cg ch ci" rel="noopener">Sign in</a></span></h4></div><div class="ky" id="lo-meta-header-sign-up-button"><div class="dd de df cx s"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_page-----954fb9b47c79---------------------nav_reg-----------" class="ba b bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq br bs bt bu bv bw" rel="noopener">Get started</a></span></div></div><a href="https://medium.com/?source=post_page-----954fb9b47c79--------------------------------" aria-label="Homepage" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="q dg"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div></div><div class="s ak"><div class="n p"><div class="ao ap aq ar as at au v"><div class="w x y z ab"><div class="dh di n o"><div class="s dj"><span class="ba b dk dl dm dn do dp dq dr ds dt du"><div class="n o"><div class="dv s"><div class="dw dx s"><div class="bv" aria-hidden="false" aria-describedby="collectionFollowPopover" aria-labelledby="collectionFollowPopover"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_page-----954fb9b47c79---------------------follow_header-----------" class="ba b bb bc dy be dz ea eb ec ed bl bm bn ee ef br bs bt bu bv bw" rel="noopener"><div class="n aw">Follow</div></a></span></div></div></div><div class="eg eh ah"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/followers?source=post_page-----954fb9b47c79--------------------------------">551K Followers</a></div><div class="eo s g">·</div><div class="eo s g"><nav class="n o"><span class="ep n ah"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/tagged/editors-pick?fromNav=true&amp;source=post_page-----954fb9b47c79--------------------------------">Editors' Picks</a></span><span class="ep n ah"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/tagged/tds-features?fromNav=true&amp;source=post_page-----954fb9b47c79--------------------------------">Features</a></span><span class="ep n ah"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/tagged/tds-explore?fromNav=true&amp;source=post_page-----954fb9b47c79--------------------------------">Explore</a></span><span class="ep n ah"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/questions-96667b06af5?source=post_page-----954fb9b47c79--------------------------------">Contribute</a></span></nav></div><div class="eo n ah g"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/about?source=post_page-----954fb9b47c79--------------------------------">About</a></div></div></span></div><div class="aj eq er ak"><button class="n o p es et eu ev" aria-label="Expand navbar"><svg width="14" height="14" class="ew"><path d="M0 .5h14M0 7h14M0 13.5h14"></path></svg></button></div></div></div></div></div></div></div><div class="ex ey ez al c fa yb fc fd fe ky an yg"><div class="n p"><div class="ao ap aq ar as at au v"><div class="fg v aj fe an cm fh"><div class="aj cm fh fi"><div class="ky" id="lo-sticky-header-sign-up-button"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_page-----954fb9b47c79---------------------nav_reg-----------" class="ba b bb bc fj be bf fk eb fl fm ed bl bm bn fn fo ef br bs bt bu bv bw" rel="noopener">Get started</a></span></div><div class="ky" id="lo-ShowPostUnderCollection-navbar-open-in-app-button"><div class="fp aj ak"><span class="ba b bb bc du"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F954fb9b47c79&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderCollection&amp;~stage=mobileNavBar&amp;source=post_page-----954fb9b47c79--------------------------------" class="fj fk bz ca cb cc cd ce cf bl fl fm cg ch ci" rel="noopener nofollow">Open in app</a></span></div></div></div><a href="https://medium.com/?source=post_page-----954fb9b47c79--------------------------------" aria-label="Homepage" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="q r"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div><div class="s hu"><div class="yn yo v ko fc yp yq ev fb yr fy" aria-hidden="true"></div><div class="ys fc yt yu yh yn ko bu yv yw yx yb yy yz za wj zb zc zd ze aj" aria-hidden="true"><div class="zh zi n o aw ck"><h2 class="ba jb zj dl gf hd">Responses (23)</h2><div class="n aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><a href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=responses-----954fb9b47c79--------------------------------" class="zk el" target="_blank" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.99 5.04c.26-.21.64-.22.91-.01.97.72 1.77 1.21 2.6 1.54.83.32 1.72.48 2.89.5.41.01.74.35.74.76-.02 3.62-.43 6.26-1.45 8.21-1.03 1.98-2.66 3.21-4.97 4.08a.75.75 0 0 1-.53 0c-2.25-.87-3.86-2.1-4.9-4.07-1.02-1.95-1.46-4.59-1.48-8.22 0-.41.33-.75.75-.76 1.19-.02 2.1-.18 2.92-.5.82-.32 1.6-.81 2.52-1.53zm.46.9c-.9.69-1.71 1.21-2.62 1.56a8.9 8.9 0 0 1-3.02.57c.03 3.45.46 5.82 1.36 7.51.88 1.69 2.25 2.77 4.28 3.57 2.1-.8 3.47-1.89 4.34-3.57.89-1.7 1.3-4.07 1.34-7.51a8.8 8.8 0 0 1-3-.57 11.8 11.8 0 0 1-2.68-1.56zm0 9.15a2.67 2.67 0 1 0 0-5.34 2.67 2.67 0 0 0 0 5.34zm0 1a3.67 3.67 0 1 0 0-7.34 3.67 3.67 0 0 0 0 7.34zm-1.82-3.77l.53-.53.91.92 1.63-1.63.52.53-2.15 2.15-1.44-1.44z"></path></svg></a></div></div><div class="s am zl"><div class="cf s am fd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" data-testid="close-button" aria-label="close"><svg width="25" height="25" viewBox="0 0 25 25" class="hx"><path d="M18.13 6.11l-5.61 5.61-5.6-5.61-.81.8 5.61 5.61-5.61 5.61.8.8 5.61-5.6 5.61 5.6.8-.8-5.6-5.6 5.6-5.62"></path></svg></button></div></div></div></div><div><h4 class="ba b bb bc hd"><div class="dl"><div class="acj zm ack s"><div class="yu acc br n ah acd ace acf"><div class="n ah"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----954fb9b47c79---------------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="acl s"><h4 class="ba b bb bc du">What are your thoughts?</h4></div></a></span><div class="ck n acg ach fb aci"><label class="n o"><div class="hw aeb aec n aed am"><input class="acm acn aco eq fb acp acq acr acs act acu acv" type="checkbox"><span class="o tg acw acx bu dy ev n dz acy p acz aea"><svg width="11" height="11" viewBox="0 0 11 11" class="dz"><path d="M0 6.31l3.7 3.7.9.91.67-1.1 5.3-8.79L8.84 0l-5.3 8.8 1.57-.2-3.7-3.7L0 6.3z"></path></svg></span></div><h4 class="ba b pb bc du">Also publish to my profile</h4></label><button class="ba b bb bc dy aee dz aef aeg aeh aei bl bm bn aej aek br bs bt bu bv bw" disabled="disabled">Respond</button></div></div></div></div></div></h4></div><div class="s"><div class="s"><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Saurav Sharma" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/00KlPuIHqxkQlV8C2.jpg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@srv902?source=responses-----954fb9b47c79----0----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Saurav Sharma</h4></a></div><a href="https://medium.com/@srv902/amazing-article-and-usually-one-of-the-overlooked-topics-479389774f15?source=responses-----954fb9b47c79----0----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">almost 2 years ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Amazing article and usually one of the overlooked topics. I do have one question — Why the calculation of variance for a single layer (cell no 18) is this</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">var += y.pow(2).mean().item()</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">but not this</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">var += (y-y.mean()).pow(2).mean().item() ?</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Thank you!!</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2F479389774f15&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----479389774f15----0-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">8<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Mehmet Alican Noyan" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Uh6thMQ3aUo219m9NucNZA.jpeg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@m.alican.noyan?source=responses-----954fb9b47c79----1----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Mehmet Alican Noyan</h4></a></div><a href="https://medium.com/@m.alican.noyan/it-is-not-easy-to-find-high-quality-articles-such-as-yours-james-thank-you-very-much-i-feel-lucky-b492458e2111?source=responses-----954fb9b47c79----1----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">over 1 year ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">It is not easy to find high quality articles such as yours James thank you very much I feel lucky today :)</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2Fb492458e2111&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----b492458e2111----1-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">4<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Guillermo Valle Pérez" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0d9rmXuXpz76FoEiU.jpg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@guillefix?source=responses-----954fb9b47c79----2----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Guillermo Valle Pérez</h4></a></div><a href="https://medium.com/@guillefix/whitening-just-ensures-that-the-inputs-have-zero-mean-and-identity-covariance-but-it-doesnt-eaf63f8520e9?source=responses-----954fb9b47c79----2----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">almost 2 years ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div role="button" tabindex="0" class="abg abh se abi abj abk ev c"><p id="embedded-quote-bd93cc674444-a600" class="abl abm gg ib b ic abn if abo abp abq abr abs abt abu is fz abv hd" data-selectable-paragraph=""><mark class="abw yj ev">It’s
 standard practice when training neural networks to ensure that our 
inputs’ values are scaled such that they fall inside such a normal 
distribution with a mean of 0 and a standard d...</mark></p></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Whitening just ensures that the inputs have zero mean and identity covariance, but it doesn’t ensure the other moments are those of a Normal distribution, so that the input distribution can still be pretty different, at higher moments.</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2Feaf63f8520e9&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----eaf63f8520e9----2-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Ayush Sahu" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1fWo10iJ0anMJcZqIXLiJSw.jpeg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@ayushsahu99?source=responses-----954fb9b47c79----3----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Ayush Sahu</h4></a></div><a href="https://medium.com/@ayushsahu99/such-a-great-article-and-it-greatly-helped-me-understanding-the-basics-of-weight-initialization-d36849b3057a?source=responses-----954fb9b47c79----3----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">about 1 year ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Such a great article and it greatly helped me understanding the basics of weight initialization. Thanks man!</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2Fd36849b3057a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----d36849b3057a----3-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Abhishek Sharma" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/2ofeLmlJX2c6Z8RWYMxs3_A.jpeg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@abhishek_shrm?source=responses-----954fb9b47c79----4----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Abhishek Sharma</h4></a></div><a href="https://medium.com/@abhishek_shrm/well-written-article-explains-the-concept-precisely-bc78817592df?source=responses-----954fb9b47c79----4----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">about 2 months ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Well written article. Explains the concept precisely.</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2Fbc78817592df&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----bc78817592df----4-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><div class="am zq zp"><div class="abx n aw o p eq aby abz aca ms acb fy"><svg width="39" height="39" viewBox="0 0 39 39"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.5 1C11.83 1 5.17 5.75 1.9 12.71L1 12.3C4.4 5.02 11.4 0 19.5 0S34.6 5.02 38 12.29l-.9.42C33.82 5.75 27.16 1 19.5 1zM1.9 26.29C5.18 33.25 11.84 38 19.5 38c7.67 0 14.33-4.75 17.6-11.71l.9.42C34.6 33.98 27.6 39 19.5 39S4.4 33.98 1 26.71l.9-.42z"></path></svg></div><img alt="Szilárd Kálosi" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_APRpbubssL0C_QkQJDMMw.png" width="32" height="32"></div><div class="abb s"><div class="n aw"><a href="https://medium.com/@kalosi.szilard?source=responses-----954fb9b47c79----5----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Szilárd Kálosi</h4></a></div><a href="https://medium.com/@kalosi.szilard/im-truly-sorry-but-you-are-comparing-apples-to-oranges-aa5510862b5e?source=responses-----954fb9b47c79----5----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">2 months ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">I'm truly sorry, but you are comparing apples to oranges. Xavier also has an initialisation based on Normal distribution. Instead of having standard devation of sqrt(2 / fan_in), they're using sqrt(2 / (fan_in+fan_out)).</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Likewise, He initialisation has a uniform pair with bounds sqrt(6 / fan_in).</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2Faa5510862b5e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----aa5510862b5e----5-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Varun Saproo" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0KoKpqCGWTK58Mjy-.jpg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@saproo?source=responses-----954fb9b47c79----6----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Varun Saproo</h4></a></div><a href="https://medium.com/@saproo/thank-you-for-this-amazing-blog-a88ba1369dcc?source=responses-----954fb9b47c79----6----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">5 months ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Thank You for this Amazing blog.</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2Fa88ba1369dcc&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----a88ba1369dcc----6-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><img alt="Marcio Teixe" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0EMFrAFQVklaDs7ru.jpg" width="32" height="32"><div class="abb s"><div class="n aw"><a href="https://medium.com/@marcioteixe?source=responses-----954fb9b47c79----7----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Marcio Teixe</h4></a></div><a href="https://medium.com/@marcioteixe/its-so-interesting-this-article-8618cfd83e57?source=responses-----954fb9b47c79----7----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">almost 2 years ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div role="button" tabindex="0" class="abg abh se abi abj abk ev c"><p id="embedded-quote-6438c70ee67b-c773" class="abl abm gg ib b ic abn if abo abp abq abr abs abt abu is fz abv hd" data-selectable-paragraph=""><mark class="abw yj ev">Alternately put: when in doubt, be courageous, try things out, and see what happens!</mark></p></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">It’s so interesting this article. It made reading all with no stop till the final paragraph. Thank you so much for sharing this and even more for your undoubtably important time.xxx</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2F8618cfd83e57&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----8618cfd83e57----7-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="nb zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><div class="am zq zp"><div class="abx n aw o p eq aby abz aca ms acb fy"><svg width="39" height="39" viewBox="0 0 39 39"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.5 1C11.83 1 5.17 5.75 1.9 12.71L1 12.3C4.4 5.02 11.4 0 19.5 0S34.6 5.02 38 12.29l-.9.42C33.82 5.75 27.16 1 19.5 1zM1.9 26.29C5.18 33.25 11.84 38 19.5 38c7.67 0 14.33-4.75 17.6-11.71l.9.42C34.6 33.98 27.6 39 19.5 39S4.4 33.98 1 26.71l.9-.42z"></path></svg></div><img alt="Daryl Chang" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0AyIsq38nWmL_zP2s.jpg" width="32" height="32"></div><div class="abb s"><div class="n aw"><a href="https://medium.com/@darylchang?source=responses-----954fb9b47c79----8----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Daryl Chang</h4></a></div><a href="https://medium.com/@darylchang/awesome-article-really-like-the-exposition-with-the-matrix-multiplication-examples-73954528a9c8?source=responses-----954fb9b47c79----8----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">9 months ago</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Awesome article, really like the exposition with the matrix multiplication examples!</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2F73954528a9c8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----73954528a9c8----8-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div><div class="al zz s"><div><div class="v ko"><div class="ti sy s"><div class="n aw ck"><div class="n o aw"><div class="am zq zp"><div class="abx n aw o p eq aby abz aca ms acb fy"><svg width="39" height="39" viewBox="0 0 39 39"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.5 1C11.83 1 5.17 5.75 1.9 12.71L1 12.3C4.4 5.02 11.4 0 19.5 0S34.6 5.02 38 12.29l-.9.42C33.82 5.75 27.16 1 19.5 1zM1.9 26.29C5.18 33.25 11.84 38 19.5 38c7.67 0 14.33-4.75 17.6-11.71l.9.42C34.6 33.98 27.6 39 19.5 39S4.4 33.98 1 26.71l.9-.42z"></path></svg></div><img alt="Abdul Hamid Merii" class="s hh zp zq" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0VVKXb1PSV4fjSfHc.jpg" width="32" height="32"></div><div class="abb s"><div class="n aw"><a href="https://amerii.medium.com/?source=responses-----954fb9b47c79----9----------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h4 class="ba b bb bc hd">Abdul Hamid Merii</h4></a></div><a href="https://amerii.medium.com/my-favorite-of-the-article-oddly-enough-is-your-conclusion-5db30105e2bc?source=responses-----954fb9b47c79----9----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener nofollow"><h4 class="ba b bb bc du">4 months ago&nbsp;(edited)</h4></a></div></div><button class="ev ns zk el aba"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="qv s"><pre class="lk"><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">My favorite part of the article, oddly enough, is your conclusion!</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">'Yes, You Can Be a Researcher'</div></h4></div><div class="abc s"><h4 class="ba b bb bc hd"><div class="dl">Couldn't agree with you more!</div></h4></div></pre></div><div class="abe n o aw ck"><div class="n o"><div class="n o"><div class="s am ho hq no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fp%2F5db30105e2bc&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=responses-----5db30105e2bc----9-----------------respond_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd">1<span class="s h g f rd re"></span></h4></div></div></div><div class="eo q n o"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en"><div class="n o"><svg width="29" height="29" class="r q abd" aria-label="responses"><path d="M21.27 20.06a9.04 9.04 0 0 0 2.75-6.68C24.02 8.21 19.67 4 14.1 4S4 8.21 4 13.38c0 5.18 4.53 9.39 10.1 9.39 1 0 2-.14 2.95-.41.28.25.6.49.92.7a7.46 7.46 0 0 0 4.19 1.3c.27 0 .5-.13.6-.35a.63.63 0 0 0-.05-.65 8.08 8.08 0 0 1-1.29-2.58 5.42 5.42 0 0 1-.15-.75zm-3.85 1.32l-.08-.28-.4.12a9.72 9.72 0 0 1-2.84.43c-4.96 0-9-3.71-9-8.27 0-4.55 4.04-8.26 9-8.26 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32a5.59 5.59 0 0 0 .21 1.29c.19.7.49 1.4.89 2.08a6.43 6.43 0 0 1-2.67-1.06c-.34-.22-.88-.48-1.16-.74z"></path></svg><span class="zr abf bv"><span class="ba b pb bc hd">1 reply</span></span></div></button></div></div><div class="hv s"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl vh cg em en">Reply</button></h4></div></div></div></div></div></div></div></div></div></div><article><section class="fq fr fs ft v fu bu s"></section><span class="s"></span><div><div class="eq fa ya fw fx fy"></div><div class="fs ft fu am"><div class="s h g f e"><aside class="yh eq fe" style="width: 291.5px;"><div class="yk te eq ael x v"><h4 class="ba b pb bc du"><span class="bv te x kp ss">Top highlight</span></h4></div></aside></div></div><section class="fz ga gb dr gc"><div class="n p"><div class="ao ap aq ar as gd au v"><div class=""><h1 id="18f9" class="ge gf gg ba gh gi gj gk gl gm gn go gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd">Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming</h1><div class="cw"><div class="n ck he hf hg"><div class="o n"><div><a href="https://medium.com/@jamesdell?source=post_page-----954fb9b47c79--------------------------------" rel="noopener"><img alt="James Dellinger" class="s hh hi hj" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1VWdH331WvzjQpoZxCJoqFA.jpeg" width="28" height="28"></a></div><div class="eo v n ct"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><a href="https://medium.com/@jamesdell?source=post_page-----954fb9b47c79--------------------------------" class="" rel="noopener"><h4 class="ba b bb bc fj">James Dellinger</h4></a></span></div></div><span class="ba b bb bc du"><a class="" rel="noopener" href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79?source=post_page-----954fb9b47c79--------------------------------"><h4 class="ba b bb bc du"><span class="hk"></span>Apr 3, 2019<span class="hl">·</span>11 min read</h4></a></span></div></div><div class="n hm hn ho hp hq hr hs ht hu"><div class="n o"><div class="hv s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="hw s"><div class="hx"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_actions_header--------------------------bookmark_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div><div class="hy s ax"></div></div></div></div></div></div><p id="4960" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq ir is fz hd" data-selectable-paragraph="">I’d
 like to invite you to join me on an exploration through different 
approaches to initializing layer weights in neural networks. 
Step-by-step, through various short experiments and thought exercises, 
we’ll discover why adequate weight initialization is so important in 
training deep neural nets. Along the way we’ll cover various approaches 
that researchers have proposed over the years, and finally drill down on
 what works best for the contemporary network architectures that you’re 
most likely to be working with.</p><p id="5721" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">The examples to follow<span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"><span id="rmm"> </span></span></span></span></span></span></span></span></span></span></span>come from my own <a href="https://nbviewer.jupyter.org/github/jamesdellinger/fastai_deep_learning_course_part2_v3/blob/master/02_fully_connected_my_reimplementation.ipynb?flush_cache=true" class="ei iy" rel="noopener nofollow">re-implementation</a> of a set of notebooks that <a href="https://www.usfca.edu/faculty/jeremy-howard" class="ei iy" rel="noopener nofollow">Jeremy Howard</a> covered in the <a href="https://www.fast.ai/2019/03/06/fastai-swift/" class="ei iy" rel="noopener nofollow">latest version</a> of fast.ai’s Deep Learning Part II course, currently <a href="https://www.usfca.edu/data-institute/certificates/deep-learning-part-two" class="ei iy" rel="noopener nofollow">being held this spring, 2019, at USF’s Data Institute</a>.</p><h2 id="a36f" class="iz ja gg ba jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hd" data-selectable-paragraph="">Why Initialize Weights</h2><p id="f4a5" class="hz ia gg ib b ic jx id ie if jy ig ih ii jz ij ik il ka im in io kb ip iq is fz hd" data-selectable-paragraph="">The
 aim of weight initialization is to prevent layer activation outputs 
from exploding or vanishing during the course of a forward pass through a
 deep neural network. If either occurs, loss gradients will either be 
too large or too small to flow backwards beneficially, and the network 
will take longer to converge, if it is even able to do so at all.</p><p id="d79e" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Matrix
 multiplication is the essential math operation of a neural network. In 
deep neural nets with several layers, one forward pass simply entails 
performing consecutive matrix multiplications at each layer, between 
that layer’s inputs and weight matrix. The product of this 
multiplication at one layer becomes the inputs of the subsequent layer, 
and so on and so forth.</p><p id="a600" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">For a quick-and-dirty example that illustrates this, let’s pretend that we have a vector <strong class="ib gh">x</strong>
 that contains some network inputs. It’s standard practice when training
 neural networks to ensure that our inputs’ values are scaled such that 
they fall inside such a normal distribution with a mean of 0 and a 
standard deviation of 1.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="ku kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ne6gE3vogzJp53lwAYxtGw_002.png" width="1400" height="90"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ne6gE3vogzJp53lwAYxtGw_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ne6gE3vogzJp53lwAYxtGw_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ne6gE3vogzJp53lwAYxtGw_006.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ne6gE3vogzJp53lwAYxtGw_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ne6gE3vogzJp53lwAYxtGw.png 700w" sizes="700px" width="1400" height="90"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*ne6gE3vogzJp53lwAYxtGw.png" width="1400" height="90" srcSet="https://miro.medium.com/max/552/1*ne6gE3vogzJp53lwAYxtGw.png 276w, https://miro.medium.com/max/1104/1*ne6gE3vogzJp53lwAYxtGw.png 552w, https://miro.medium.com/max/1280/1*ne6gE3vogzJp53lwAYxtGw.png 640w, https://miro.medium.com/max/1400/1*ne6gE3vogzJp53lwAYxtGw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="f011" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Let’s also pretend that we have a simple 100-layer network with no activations , and that each layer has a matrix <strong class="ib gh">a</strong>
 that contains the layer’s weights. In order to complete a single 
forward pass we’ll have to perform a matrix multiplication between layer
 inputs and weights at each of the hundred layers, which will make for a
 grand total of <em class="kz">100</em> consecutive matrix multiplications.</p><p id="efc6" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">It
 turns out that initializing the values of layer weights from the same 
standard normal distribution to which we scaled our inputs is never a 
good idea. To see why, we can simulate a forward pass through our 
hypothetical network.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="la kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1IK15xc15E1LJGlDP1FEXFA_002.png" width="1400" height="270"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1IK15xc15E1LJGlDP1FEXFA.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1IK15xc15E1LJGlDP1FEXFA_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1IK15xc15E1LJGlDP1FEXFA_006.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1IK15xc15E1LJGlDP1FEXFA_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1IK15xc15E1LJGlDP1FEXFA_003.png 700w" sizes="700px" width="1400" height="270"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*IK15xc15E1LJGlDP1FEXFA.png" width="1400" height="270" srcSet="https://miro.medium.com/max/552/1*IK15xc15E1LJGlDP1FEXFA.png 276w, https://miro.medium.com/max/1104/1*IK15xc15E1LJGlDP1FEXFA.png 552w, https://miro.medium.com/max/1280/1*IK15xc15E1LJGlDP1FEXFA.png 640w, https://miro.medium.com/max/1400/1*IK15xc15E1LJGlDP1FEXFA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="6f3f" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Whoa!
 Somewhere during those 100 multiplications, the layer outputs got so 
big that even the computer wasn’t able to recognize their standard 
deviation and mean as numbers. We can actually see exactly how long that
 took to happen.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lb kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_yr6lnXY-1aXVUWb1MJIYA_003.png" width="1400" height="398"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_yr6lnXY-1aXVUWb1MJIYA.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_yr6lnXY-1aXVUWb1MJIYA_005.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_yr6lnXY-1aXVUWb1MJIYA_006.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_yr6lnXY-1aXVUWb1MJIYA_004.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_yr6lnXY-1aXVUWb1MJIYA_002.png 700w" sizes="700px" width="1400" height="398"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*_yr6lnXY-1aXVUWb1MJIYA.png" width="1400" height="398" srcSet="https://miro.medium.com/max/552/1*_yr6lnXY-1aXVUWb1MJIYA.png 276w, https://miro.medium.com/max/1104/1*_yr6lnXY-1aXVUWb1MJIYA.png 552w, https://miro.medium.com/max/1280/1*_yr6lnXY-1aXVUWb1MJIYA.png 640w, https://miro.medium.com/max/1400/1*_yr6lnXY-1aXVUWb1MJIYA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="0ba2" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">The activation outputs exploded within 29 of our network’s layers. We clearly initialized our weights to be too large.</p><p id="ab92" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Unfortunately,
 we also have to worry about preventing layer outputs from vanishing. To
 see what happens when we initialize network weights to be too small — 
we’ll scale our weight values such that, while they still fall inside a 
normal distribution with a mean of 0, they have a standard deviation of 
0.01.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lc kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1z89-cC4jCGPOkp3cnbyr8A_002.png" width="1400" height="360"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1z89-cC4jCGPOkp3cnbyr8A.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1z89-cC4jCGPOkp3cnbyr8A_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1z89-cC4jCGPOkp3cnbyr8A_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1z89-cC4jCGPOkp3cnbyr8A_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1z89-cC4jCGPOkp3cnbyr8A_003.png 700w" sizes="700px" width="1400" height="360"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*z89-cC4jCGPOkp3cnbyr8A.png" width="1400" height="360" srcSet="https://miro.medium.com/max/552/1*z89-cC4jCGPOkp3cnbyr8A.png 276w, https://miro.medium.com/max/1104/1*z89-cC4jCGPOkp3cnbyr8A.png 552w, https://miro.medium.com/max/1280/1*z89-cC4jCGPOkp3cnbyr8A.png 640w, https://miro.medium.com/max/1400/1*z89-cC4jCGPOkp3cnbyr8A.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="6271" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">During the course of the above hypothetical forward pass, the activation outputs completely vanished.</p><p id="08c0" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">To
 sum it up, if weights are initialized too large, the network won’t 
learn well. The same happens when weights are initialized too small.</p><h2 id="da92" class="iz ja gg ba jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hd" data-selectable-paragraph="">How can we find the sweet spot?</h2><p id="7698" class="hz ia gg ib b ic jx id ie if jy ig ih ii jz ij ik il ka im in io kb ip iq is fz hd" data-selectable-paragraph="">Remember
 that as mentioned above, the math required to complete a forward pass 
through a neural network entails nothing more than a succession of 
matrix multiplications. If we have an output <strong class="ib gh">y</strong> that is the product of a matrix multiplication between our input vector <strong class="ib gh">x</strong> and weight matrix <strong class="ib gh">a</strong>, each element <em class="kz">i</em> in <strong class="ib gh">y</strong> is defined as</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="ld kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1K3AIFVUelCr0z646zrQjPw_003.png" width="1400" height="212"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1K3AIFVUelCr0z646zrQjPw_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1K3AIFVUelCr0z646zrQjPw_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1K3AIFVUelCr0z646zrQjPw_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1K3AIFVUelCr0z646zrQjPw_004.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1K3AIFVUelCr0z646zrQjPw.png 700w" sizes="700px" width="1400" height="212"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*K3AIFVUelCr0z646zrQjPw.png" width="1400" height="212" srcSet="https://miro.medium.com/max/552/1*K3AIFVUelCr0z646zrQjPw.png 276w, https://miro.medium.com/max/1104/1*K3AIFVUelCr0z646zrQjPw.png 552w, https://miro.medium.com/max/1280/1*K3AIFVUelCr0z646zrQjPw.png 640w, https://miro.medium.com/max/1400/1*K3AIFVUelCr0z646zrQjPw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="15e5" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">where <em class="kz">i</em> is a given row-index of weight matrix <strong class="ib gh">a</strong>, <em class="kz">k</em> is both a given column-index in weight matrix <strong class="ib gh">a</strong> and element-index in input vector <strong class="ib gh">x</strong>, and <em class="kz">n</em> is the range or total number of elements in <strong class="ib gh">x</strong>. This can also be defined in Python as:</p><pre class="kd ke kf kg kh le lf lg"><span id="316e" class="hd iz ja gg lh b dk li lj s lk" data-selectable-paragraph="">y[i] = sum([c*d for c,d in zip(a[i], x)])</span></pre><p id="d276" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">We can demonstrate that at a given layer, the matrix product of our inputs <strong class="ib gh">x</strong> and weight matrix <strong class="ib gh">a</strong>
 that we initialized from a standard normal distribution will, on 
average, have a standard deviation very close to the square root of the 
number of input connections, which in our example is √512.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="ll kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1oJDRa2HOPhe5JV7co5Ig-A.png" width="1400" height="616"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1oJDRa2HOPhe5JV7co5Ig-A_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1oJDRa2HOPhe5JV7co5Ig-A_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1oJDRa2HOPhe5JV7co5Ig-A_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1oJDRa2HOPhe5JV7co5Ig-A_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1oJDRa2HOPhe5JV7co5Ig-A_002.png 700w" sizes="700px" width="1400" height="616"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*oJDRa2HOPhe5JV7co5Ig-A.png" width="1400" height="616" srcSet="https://miro.medium.com/max/552/1*oJDRa2HOPhe5JV7co5Ig-A.png 276w, https://miro.medium.com/max/1104/1*oJDRa2HOPhe5JV7co5Ig-A.png 552w, https://miro.medium.com/max/1280/1*oJDRa2HOPhe5JV7co5Ig-A.png 640w, https://miro.medium.com/max/1400/1*oJDRa2HOPhe5JV7co5Ig-A.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="6b2f" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">This property isn’t surprising if we view it in terms of how matrix multiplication is defined: in order to calculate <strong class="ib gh">y</strong> we sum 512 products of the element-wise multiplication of one element of the inputs <strong class="ib gh">x</strong> by one column of the weights <strong class="ib gh">a</strong>. In our example where both <strong class="ib gh">x</strong> and <strong class="ib gh">a</strong>
 are initialized using standard normal distributions, each of these 512 
products would have a mean of 0 and standard deviation of 1.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lm kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1wMTdWrSPOXh8C6XxoSO7pg_003.png" width="1400" height="444"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1wMTdWrSPOXh8C6XxoSO7pg.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1wMTdWrSPOXh8C6XxoSO7pg_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1wMTdWrSPOXh8C6XxoSO7pg_006.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1wMTdWrSPOXh8C6XxoSO7pg_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1wMTdWrSPOXh8C6XxoSO7pg_002.png 700w" sizes="700px" width="1400" height="444"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*wMTdWrSPOXh8C6XxoSO7pg.png" width="1400" height="444" srcSet="https://miro.medium.com/max/552/1*wMTdWrSPOXh8C6XxoSO7pg.png 276w, https://miro.medium.com/max/1104/1*wMTdWrSPOXh8C6XxoSO7pg.png 552w, https://miro.medium.com/max/1280/1*wMTdWrSPOXh8C6XxoSO7pg.png 640w, https://miro.medium.com/max/1400/1*wMTdWrSPOXh8C6XxoSO7pg.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="0a28" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">It then follows that the <em class="kz">sum</em> of these 512 products would have a mean of 0, variance of 512, and therefore a standard deviation of √512.</p><p id="b501" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">And
 this is why in our example above we saw our layer outputs exploding 
after 29 consecutive matrix multiplications. In the case of our 
bare-bones 100-layer network architecture, what we’d like is for each 
layer’s outputs to have a standard deviation of about 1. This 
conceivably would allow us to repeat matrix multiplications across as 
many network layers as we want, without activations exploding or 
vanishing.</p><p id="95b6" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">If we first scale the weight matrix <strong class="ib gh">a</strong> by dividing all its randomly chosen values by √512, the element-wise multiplication that fills in one element of the outputs <strong class="ib gh">y</strong> would now, on average, have a variance of only 1/√512.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="ln kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1qDpw22Z8XSDZe5MLLOLUew_002.png" width="1400" height="618"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1qDpw22Z8XSDZe5MLLOLUew.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1qDpw22Z8XSDZe5MLLOLUew_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1qDpw22Z8XSDZe5MLLOLUew_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1qDpw22Z8XSDZe5MLLOLUew_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1qDpw22Z8XSDZe5MLLOLUew_003.png 700w" sizes="700px" width="1400" height="618"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*qDpw22Z8XSDZe5MLLOLUew.png" width="1400" height="618" srcSet="https://miro.medium.com/max/552/1*qDpw22Z8XSDZe5MLLOLUew.png 276w, https://miro.medium.com/max/1104/1*qDpw22Z8XSDZe5MLLOLUew.png 552w, https://miro.medium.com/max/1280/1*qDpw22Z8XSDZe5MLLOLUew.png 640w, https://miro.medium.com/max/1400/1*qDpw22Z8XSDZe5MLLOLUew.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="ac76" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">This means that the standard deviation of the matrix <strong class="ib gh">y</strong>, which contains each of the 512 values that are generated by way of the matrix multiplication between inputs <strong class="ib gh">x</strong> and weights <strong class="ib gh">a</strong>, would be 1. Let’s confirm this experimentally.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lm kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15LAW2b1nDhPB9k7gt68yZg.png" width="1400" height="444"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15LAW2b1nDhPB9k7gt68yZg_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15LAW2b1nDhPB9k7gt68yZg_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15LAW2b1nDhPB9k7gt68yZg_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15LAW2b1nDhPB9k7gt68yZg_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15LAW2b1nDhPB9k7gt68yZg_003.png 700w" sizes="700px" width="1400" height="444"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*5LAW2b1nDhPB9k7gt68yZg.png" width="1400" height="444" srcSet="https://miro.medium.com/max/552/1*5LAW2b1nDhPB9k7gt68yZg.png 276w, https://miro.medium.com/max/1104/1*5LAW2b1nDhPB9k7gt68yZg.png 552w, https://miro.medium.com/max/1280/1*5LAW2b1nDhPB9k7gt68yZg.png 640w, https://miro.medium.com/max/1400/1*5LAW2b1nDhPB9k7gt68yZg.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="a5c0" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Now
 let’s re-run our quick-and-dirty 100-layer network. As before, we first
 choose layer weights at random from standard normal distribution inside
 [-1,1], but this time we scale those weights by 1/√<em class="kz">n</em>, where <em class="kz">n</em> is the number of network input connections at a layer, which is 512 in our example.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lc kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/18-f9bmfeVVWwLLqSoQADSA.png" width="1400" height="360"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/18-f9bmfeVVWwLLqSoQADSA_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/18-f9bmfeVVWwLLqSoQADSA_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/18-f9bmfeVVWwLLqSoQADSA_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/18-f9bmfeVVWwLLqSoQADSA_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/18-f9bmfeVVWwLLqSoQADSA_002.png 700w" sizes="700px" width="1400" height="360"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*8-f9bmfeVVWwLLqSoQADSA.png" width="1400" height="360" srcSet="https://miro.medium.com/max/552/1*8-f9bmfeVVWwLLqSoQADSA.png 276w, https://miro.medium.com/max/1104/1*8-f9bmfeVVWwLLqSoQADSA.png 552w, https://miro.medium.com/max/1280/1*8-f9bmfeVVWwLLqSoQADSA.png 640w, https://miro.medium.com/max/1400/1*8-f9bmfeVVWwLLqSoQADSA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="b143" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Success! Our layer outputs neither exploded nor vanished, even after 100 of our hypothetical layers.</p><p id="57e4" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">While
 at first glance it may seem like at this point we can call it a day, 
real-world neural networks aren’t quite as simple as our first example 
may seem to indicate. For the sake of simplicity, activation functions 
were omitted. However, we’d never do this in real life. It’s thanks to 
the placement of these non-linear activation functions at the tail end 
of network layers, that deep neural nets are able create close 
approximations of intricate functions that describe real-world 
phenomena, which can then be used to generate astoundingly impressive 
predictions, such as the classification of handwriting samples.</p><h2 id="169e" class="iz ja gg ba jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hd" data-selectable-paragraph="">Xavier Initialization</h2><p id="3231" class="hz ia gg ib b ic jx id ie if jy ig ih ii jz ij ik il ka im in io kb ip iq is fz hd" data-selectable-paragraph="">Up
 until a few years ago, most commonly used activation functions were 
symmetric about a given value, and had ranges that asymptotically 
approached values that were plus/minus a certain distance from this 
midpoint. The hyperbolic tangent and softsign functions exemplify this 
class of activations.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div class="fs ft lo"><div class="ks s am kt"><div class="lp kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/139Dm-zzV98YO-WKCfXgeVg.png" width="371" height="264"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/139Dm-zzV98YO-WKCfXgeVg_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/139Dm-zzV98YO-WKCfXgeVg_003.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/139Dm-zzV98YO-WKCfXgeVg_002.png 371w" sizes="371px" width="371" height="264"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/742/1*39Dm-zzV98YO-WKCfXgeVg.png" width="371" height="264" srcSet="https://miro.medium.com/max/552/1*39Dm-zzV98YO-WKCfXgeVg.png 276w, https://miro.medium.com/max/742/1*39Dm-zzV98YO-WKCfXgeVg.png 371w" sizes="371px"/></noscript></div></div></div><figcaption class="lq lr fu fs ft ls lt ba b bb bc du" data-selectable-paragraph="">Tanh and softsign activation functions. Credit: Sefik Ilkin Serengil’s <a href="https://sefiks.com/2017/11/10/softsign-as-a-neural-networks-activation-function/" class="ei iy" rel="noopener nofollow">blog.</a></figcaption></figure><p id="5a52" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">We’ll
 add a hyperbolic tangent activation function after each layer our 
hypothetical 100-layer network, and then see what happens when we use 
our home-grown weight initialization scheme where layer weights are 
scaled by 1/√<em class="kz">n.</em></p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lu kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15Ko4_sp9-58wK_hFL2GCHQ.png" width="1400" height="464"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15Ko4_sp9-58wK_hFL2GCHQ_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15Ko4_sp9-58wK_hFL2GCHQ_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15Ko4_sp9-58wK_hFL2GCHQ_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15Ko4_sp9-58wK_hFL2GCHQ_004.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/15Ko4_sp9-58wK_hFL2GCHQ_003.png 700w" sizes="700px" width="1400" height="464"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*5Ko4_sp9-58wK_hFL2GCHQ.png" width="1400" height="464" srcSet="https://miro.medium.com/max/552/1*5Ko4_sp9-58wK_hFL2GCHQ.png 276w, https://miro.medium.com/max/1104/1*5Ko4_sp9-58wK_hFL2GCHQ.png 552w, https://miro.medium.com/max/1280/1*5Ko4_sp9-58wK_hFL2GCHQ.png 640w, https://miro.medium.com/max/1400/1*5Ko4_sp9-58wK_hFL2GCHQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="d3a0" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">The
 standard deviation of activation outputs of the 100th layer is down to 
about 0.06. This is definitely on the small side, but at least 
activations haven’t totally vanished!</p><p id="fafa" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">As
 intuitive as the journey to discovering our home-grown weight init 
strategy may now seem in retrospect, you may be surprised to hear that 
as recently as 2010, this was not the conventional approach for 
initializing weight layers.</p><p id="04d8" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">When Xavier Glorot and Yoshua Bengio published their landmark paper titled <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" class="ei iy" rel="noopener nofollow"><em class="kz">Understanding the difficulty of training deep feedforward neural networks</em></a>, the “commonly used heuristic” to which they compared their experiments was that of initializing weights from a <em class="kz">uniform</em> distribution in [-1,1] and then scaling by 1/√<em class="kz">n</em>.</p><p id="7aad" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">It turns out this “standard” approach doesn’t actually work that well.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lv kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RJ2AxAObnSszBlJ6_LZKrQ_002.png" width="1400" height="330"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RJ2AxAObnSszBlJ6_LZKrQ.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RJ2AxAObnSszBlJ6_LZKrQ_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RJ2AxAObnSszBlJ6_LZKrQ_006.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RJ2AxAObnSszBlJ6_LZKrQ_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RJ2AxAObnSszBlJ6_LZKrQ_003.png 700w" sizes="700px" width="1400" height="330"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*RJ2AxAObnSszBlJ6_LZKrQ.png" width="1400" height="330" srcSet="https://miro.medium.com/max/552/1*RJ2AxAObnSszBlJ6_LZKrQ.png 276w, https://miro.medium.com/max/1104/1*RJ2AxAObnSszBlJ6_LZKrQ.png 552w, https://miro.medium.com/max/1280/1*RJ2AxAObnSszBlJ6_LZKrQ.png 640w, https://miro.medium.com/max/1400/1*RJ2AxAObnSszBlJ6_LZKrQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="33ac" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Re-running
 our 100-layer tanh network with “standard” weight initialization caused
 activation gradients to become infinitesimally small — they’re just 
about as good as vanished.</p><p id="43db" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">This
 poor performance is actually what spurred Glorot and Bengio to propose 
their own weight initialization strategy, which they referred to as 
“normalized initialization” in their paper, and which is now popularly 
termed “Xavier initialization.”</p><p id="54ed" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph=""><mark class="yi yj ev">Xavier initialization sets a layer’s weights to values chosen from a random uniform distribution that’s bounded between</mark></p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lw kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1H6t3yYBLlinNRUwmL-d7vw_003.png" width="1400" height="226"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1H6t3yYBLlinNRUwmL-d7vw.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1H6t3yYBLlinNRUwmL-d7vw_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1H6t3yYBLlinNRUwmL-d7vw_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1H6t3yYBLlinNRUwmL-d7vw_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1H6t3yYBLlinNRUwmL-d7vw_002.png 700w" sizes="700px" width="1400" height="226"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*H6t3yYBLlinNRUwmL-d7vw.png" width="1400" height="226" srcSet="https://miro.medium.com/max/552/1*H6t3yYBLlinNRUwmL-d7vw.png 276w, https://miro.medium.com/max/1104/1*H6t3yYBLlinNRUwmL-d7vw.png 552w, https://miro.medium.com/max/1280/1*H6t3yYBLlinNRUwmL-d7vw.png 640w, https://miro.medium.com/max/1400/1*H6t3yYBLlinNRUwmL-d7vw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="9c07" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">where <em class="kz">nᵢ</em> is the number of incoming network connections, or “fan-in,” to the layer, and <em class="kz">nᵢ₊₁</em> is the number of outgoing network connections from that layer, also known as the “fan-out.”</p><p id="9fb4" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Glorot
 and Bengio believed that Xavier weight initialization would maintain 
the variance of activations and back-propagated gradients all the way up
 or down the layers of a network. In their experiments they observed 
that Xavier initialization enabled a 5-layer network to maintain near 
identical variances of its weight gradients across layers.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lx kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Gelf2ZcKYowsLf5FT4n0BQ_003.png" width="1400" height="474"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Gelf2ZcKYowsLf5FT4n0BQ_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Gelf2ZcKYowsLf5FT4n0BQ_005.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Gelf2ZcKYowsLf5FT4n0BQ_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Gelf2ZcKYowsLf5FT4n0BQ_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Gelf2ZcKYowsLf5FT4n0BQ.png 700w" sizes="700px" width="1400" height="474"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*Gelf2ZcKYowsLf5FT4n0BQ.png" width="1400" height="474" srcSet="https://miro.medium.com/max/552/1*Gelf2ZcKYowsLf5FT4n0BQ.png 276w, https://miro.medium.com/max/1104/1*Gelf2ZcKYowsLf5FT4n0BQ.png 552w, https://miro.medium.com/max/1280/1*Gelf2ZcKYowsLf5FT4n0BQ.png 640w, https://miro.medium.com/max/1400/1*Gelf2ZcKYowsLf5FT4n0BQ.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="lq lr fu fs ft ls lt ba b bb bc du" data-selectable-paragraph="">With Xavier init. Credit: <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" class="ei iy" rel="noopener nofollow">Glorot &amp; Bengio</a>.</figcaption></figure><p id="b727" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Conversely,
 it turned out that using “standard” initialization brought about a much
 bigger gap in variance between weight gradients at the network’s lower 
layers, which were higher, and those at its top-most layers, which were 
approaching zero.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="ly kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1mDilNz4ADDbbr8Qb4d4RqQ.png" width="1400" height="480"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1mDilNz4ADDbbr8Qb4d4RqQ_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1mDilNz4ADDbbr8Qb4d4RqQ_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1mDilNz4ADDbbr8Qb4d4RqQ_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1mDilNz4ADDbbr8Qb4d4RqQ_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1mDilNz4ADDbbr8Qb4d4RqQ_002.png 700w" sizes="700px" width="1400" height="480"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*mDilNz4ADDbbr8Qb4d4RqQ.png" width="1400" height="480" srcSet="https://miro.medium.com/max/552/1*mDilNz4ADDbbr8Qb4d4RqQ.png 276w, https://miro.medium.com/max/1104/1*mDilNz4ADDbbr8Qb4d4RqQ.png 552w, https://miro.medium.com/max/1280/1*mDilNz4ADDbbr8Qb4d4RqQ.png 640w, https://miro.medium.com/max/1400/1*mDilNz4ADDbbr8Qb4d4RqQ.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="lq lr fu fs ft ls lt ba b bb bc du" data-selectable-paragraph="">Without Xavier init. Credit: <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" class="ei iy" rel="noopener nofollow">Glorot &amp; Bengio</a>.</figcaption></figure><p id="fc04" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">To
 drive the point home, Glorot and Bengio demonstrated that networks 
initialized with Xavier achieved substantially quicker convergence and 
higher accuracy on the <a href="https://www.cs.toronto.edu/~kriz/cifar.html" class="ei iy" rel="noopener nofollow">CIFAR-10 image classification task</a>.</p><p id="4c2a" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Let’s re-run our 100-layer tanh network once more, this time using Xavier initialization:</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="lz kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/13NiBW8yi-gYrOpsy70PNEg.png" width="1400" height="450"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/13NiBW8yi-gYrOpsy70PNEg_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/13NiBW8yi-gYrOpsy70PNEg_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/13NiBW8yi-gYrOpsy70PNEg_006.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/13NiBW8yi-gYrOpsy70PNEg_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/13NiBW8yi-gYrOpsy70PNEg_003.png 700w" sizes="700px" width="1400" height="450"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*3NiBW8yi-gYrOpsy70PNEg.png" width="1400" height="450" srcSet="https://miro.medium.com/max/552/1*3NiBW8yi-gYrOpsy70PNEg.png 276w, https://miro.medium.com/max/1104/1*3NiBW8yi-gYrOpsy70PNEg.png 552w, https://miro.medium.com/max/1280/1*3NiBW8yi-gYrOpsy70PNEg.png 640w, https://miro.medium.com/max/1400/1*3NiBW8yi-gYrOpsy70PNEg.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="92d5" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">In
 our experimental network, Xavier initialization performs pretty 
identical to the home-grown method that we derived earlier, where we 
sampled values from a random normal distribution and scaled by the 
square root of number of incoming network connections, <em class="kz">n</em>.</p><h2 id="9dba" class="iz ja gg ba jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hd" data-selectable-paragraph="">Kaiming Initialization</h2><p id="e8d9" class="hz ia gg ib b ic jx id ie if jy ig ih ii jz ij ik il ka im in io kb ip iq is fz hd" data-selectable-paragraph="">Conceptually,
 it makes sense that when using activation functions that are symmetric 
about zero and have outputs inside [-1,1], such as softsign and tanh, 
we’d want the activation outputs of each layer to have a mean of 0 and a
 standard deviation around 1, on average. This is precisely what our 
home-grown method and Xavier both enable.</p><p id="863f" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">But
 what if we’re using ReLU activation functions? Would it still make 
sense to want to scale random initial weight values in the same way?</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div class="fs ft ma"><div class="ks s am kt"><div class="mb kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1njuH4XVXf-l9pR_RorUOrA_002.png" width="357" height="278"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1njuH4XVXf-l9pR_RorUOrA.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1njuH4XVXf-l9pR_RorUOrA_003.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1njuH4XVXf-l9pR_RorUOrA.png 357w" sizes="357px" width="357" height="278"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/714/1*njuH4XVXf-l9pR_RorUOrA.png" width="357" height="278" srcSet="https://miro.medium.com/max/552/1*njuH4XVXf-l9pR_RorUOrA.png 276w, https://miro.medium.com/max/714/1*njuH4XVXf-l9pR_RorUOrA.png 357w" sizes="357px"/></noscript></div></div></div><figcaption class="lq lr fu fs ft ls lt ba b bb bc du" data-selectable-paragraph="">ReLU activation function. Credit: Kanchan Sarkar’s <a href="https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec" class="ei iy" rel="noopener">blog</a>.</figcaption></figure><p id="6233" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">To
 see what would happen, let’s use a ReLU activation instead of tanh in 
one of our hypothetical network’s layers and observe the expected 
standard deviation of its outputs.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="mc kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10C5Beclgsv-_HEaOfV8eJA.png" width="1400" height="552"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10C5Beclgsv-_HEaOfV8eJA_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10C5Beclgsv-_HEaOfV8eJA_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10C5Beclgsv-_HEaOfV8eJA_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10C5Beclgsv-_HEaOfV8eJA_005.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10C5Beclgsv-_HEaOfV8eJA_002.png 700w" sizes="700px" width="1400" height="552"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*0C5Beclgsv-_HEaOfV8eJA.png" width="1400" height="552" srcSet="https://miro.medium.com/max/552/1*0C5Beclgsv-_HEaOfV8eJA.png 276w, https://miro.medium.com/max/1104/1*0C5Beclgsv-_HEaOfV8eJA.png 552w, https://miro.medium.com/max/1280/1*0C5Beclgsv-_HEaOfV8eJA.png 640w, https://miro.medium.com/max/1400/1*0C5Beclgsv-_HEaOfV8eJA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="1765" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">It
 turns out that when using a ReLU activation, a single layer will, on 
average have standard deviation that’s very close to the square root of 
the number of input connections, <em class="kz">divided by the square root of two</em>, or √512/√2 in our example.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="md kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1dZ5UcHx2RTeLXL46YxKgbw.png" width="1400" height="146"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1dZ5UcHx2RTeLXL46YxKgbw_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1dZ5UcHx2RTeLXL46YxKgbw_005.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1dZ5UcHx2RTeLXL46YxKgbw_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1dZ5UcHx2RTeLXL46YxKgbw_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1dZ5UcHx2RTeLXL46YxKgbw_002.png 700w" sizes="700px" width="1400" height="146"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*dZ5UcHx2RTeLXL46YxKgbw.png" width="1400" height="146" srcSet="https://miro.medium.com/max/552/1*dZ5UcHx2RTeLXL46YxKgbw.png 276w, https://miro.medium.com/max/1104/1*dZ5UcHx2RTeLXL46YxKgbw.png 552w, https://miro.medium.com/max/1280/1*dZ5UcHx2RTeLXL46YxKgbw.png 640w, https://miro.medium.com/max/1400/1*dZ5UcHx2RTeLXL46YxKgbw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="edc4" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Scaling the values of the weight matrix <strong class="ib gh">a</strong> by this number will cause each individual ReLU layer to have a standard deviation of 1 on average.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="me kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/11G5dke8TAGumS88OKa3TfA_003.png" width="1400" height="446"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/11G5dke8TAGumS88OKa3TfA_002.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/11G5dke8TAGumS88OKa3TfA_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/11G5dke8TAGumS88OKa3TfA_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/11G5dke8TAGumS88OKa3TfA_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/11G5dke8TAGumS88OKa3TfA.png 700w" sizes="700px" width="1400" height="446"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*1G5dke8TAGumS88OKa3TfA.png" width="1400" height="446" srcSet="https://miro.medium.com/max/552/1*1G5dke8TAGumS88OKa3TfA.png 276w, https://miro.medium.com/max/1104/1*1G5dke8TAGumS88OKa3TfA.png 552w, https://miro.medium.com/max/1280/1*1G5dke8TAGumS88OKa3TfA.png 640w, https://miro.medium.com/max/1400/1*1G5dke8TAGumS88OKa3TfA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="f1cf" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">As
 we showed before, keeping the standard deviation of layers’ activations
 around 1 will allow us to stack several more layers in a deep neural 
network without gradients exploding or vanishing.</p><p id="3f29" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">This
 exploration into how to best initialize weights in networks with 
ReLU-like activations is what motivated Kaiming He et. al. to <a href="https://arxiv.org/pdf/1502.01852.pdf" class="ei iy" rel="noopener nofollow">propose their own initialization scheme</a> that’s tailored for deep neural nets that use these kinds of asymmetric, non-linear activations.</p><p id="f0db" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">In
 their 2015 paper, He et. al. demonstrated that deep networks (e.g. a 
22-layer CNN) would converge much earlier if the following input weight 
initialization strategy is employed:</p><ol class=""><li id="1f94" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is mf mg mh hd" data-selectable-paragraph="">Create
 a tensor with the dimensions appropriate for a weight matrix at a given
 layer, and populate it with numbers randomly chosen from a standard 
normal distribution.</li><li id="e8ea" class="hz ia gg ib b ic mi id ie if mj ig ih ii mk ij ik il ml im in io mm ip iq is mf mg mh hd" data-selectable-paragraph="">Multiply each randomly chosen number by <em class="kz">√</em>2/<em class="kz">√n</em> where <em class="kz">n</em> is the number of incoming connections coming into a given layer from the previous layer’s output (also known as the “fan-in”).</li><li id="0e8d" class="hz ia gg ib b ic mi id ie if mj ig ih ii mk ij ik il ml im in io mm ip iq is mf mg mh hd" data-selectable-paragraph="">Bias tensors are initialized to zero.</li></ol><p id="bc86" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">We
 can follow these directions to implement our own version of Kaiming 
initialization and verify that it can indeed prevent activation outputs 
from exploding or vanishing if ReLU is used at all layers of our 
hypothetical 100-layer network.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="mn kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RD_c4ayThCkRvODAIMfOEQ.png" width="1400" height="506"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RD_c4ayThCkRvODAIMfOEQ_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RD_c4ayThCkRvODAIMfOEQ_005.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RD_c4ayThCkRvODAIMfOEQ_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RD_c4ayThCkRvODAIMfOEQ_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1RD_c4ayThCkRvODAIMfOEQ_002.png 700w" sizes="700px" width="1400" height="506"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*RD_c4ayThCkRvODAIMfOEQ.png" width="1400" height="506" srcSet="https://miro.medium.com/max/552/1*RD_c4ayThCkRvODAIMfOEQ.png 276w, https://miro.medium.com/max/1104/1*RD_c4ayThCkRvODAIMfOEQ.png 552w, https://miro.medium.com/max/1280/1*RD_c4ayThCkRvODAIMfOEQ.png 640w, https://miro.medium.com/max/1400/1*RD_c4ayThCkRvODAIMfOEQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="dbc9" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">As a final comparison, here’s what would happen if we were to use Xavier initialization, instead.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="mo kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_1RKMYJbwsIa4SYAj8ol-A_003.png" width="1400" height="366"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_1RKMYJbwsIa4SYAj8ol-A.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_1RKMYJbwsIa4SYAj8ol-A_004.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_1RKMYJbwsIa4SYAj8ol-A_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_1RKMYJbwsIa4SYAj8ol-A_006.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1_1RKMYJbwsIa4SYAj8ol-A_002.png 700w" sizes="700px" width="1400" height="366"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*_1RKMYJbwsIa4SYAj8ol-A.png" width="1400" height="366" srcSet="https://miro.medium.com/max/552/1*_1RKMYJbwsIa4SYAj8ol-A.png 276w, https://miro.medium.com/max/1104/1*_1RKMYJbwsIa4SYAj8ol-A.png 552w, https://miro.medium.com/max/1280/1*_1RKMYJbwsIa4SYAj8ol-A.png 640w, https://miro.medium.com/max/1400/1*_1RKMYJbwsIa4SYAj8ol-A.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="ff7b" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Ouch! When using Xavier to initialize weights, activation outputs have almost completely vanished by the 100th layer!</p><p id="944b" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Incidentally,
 when they trained even deeper networks that used ReLUs, He et. al. 
found that a 30-layer CNN using Xavier initialization stalled completely
 and didn’t learn at all. However, when the same network was initialized
 according to the three-step procedure outlined above, it enjoyed 
substantially greater convergence.</p><figure class="kd ke kf kg kh ki fs ft paragraph-image"><div role="button" tabindex="0" class="kj kk am kl v km"><div class="fs ft kc"><div class="ks s am kt"><div class="mp kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AcZIzXFAJm_ZafRKleF_0g.png" width="1400" height="810"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AcZIzXFAJm_ZafRKleF_0g_003.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AcZIzXFAJm_ZafRKleF_0g_006.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AcZIzXFAJm_ZafRKleF_0g_005.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AcZIzXFAJm_ZafRKleF_0g_004.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1AcZIzXFAJm_ZafRKleF_0g_002.png 700w" sizes="700px" width="1400" height="810"><noscript><img alt="Image for post" class="eq fe fa ko v" src="https://miro.medium.com/max/2800/1*AcZIzXFAJm_ZafRKleF_0g.png" width="1400" height="810" srcSet="https://miro.medium.com/max/552/1*AcZIzXFAJm_ZafRKleF_0g.png 276w, https://miro.medium.com/max/1104/1*AcZIzXFAJm_ZafRKleF_0g.png 552w, https://miro.medium.com/max/1280/1*AcZIzXFAJm_ZafRKleF_0g.png 640w, https://miro.medium.com/max/1400/1*AcZIzXFAJm_ZafRKleF_0g.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="lq lr fu fs ft ls lt ba b bb bc du" data-selectable-paragraph="">Convergence of a <strong class="ba jb">30-layer</strong> CNN thanks to Kaiming init. Credit: <a href="https://arxiv.org/pdf/1502.01852.pdf" class="ei iy" rel="noopener nofollow">He et. al.</a></figcaption></figure><p id="049e" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">The
 moral of the story for us is that any network we train from scratch, 
especially for computer vision applications, will almost certainly 
contain ReLU activation functions and be several layers deep. In such 
cases, Kaiming should be our go-to weight init strategy.</p><h2 id="e55f" class="iz ja gg ba jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hd" data-selectable-paragraph="">Yes, You Too Can Be a Researcher</h2><p id="343f" class="hz ia gg ib b ic jx id ie if jy ig ih ii jz ij ik il ka im in io kb ip iq is fz hd" data-selectable-paragraph="">Even
 more importantly, I’m not ashamed to admit that I felt intimidated when
 I saw the Xavier and Kaiming formulas for the first time. What with 
their respective square roots of six and two, part of me couldn’t help 
but feel like they must have been the result of some sort of oracular 
wisdom I couldn’t hope to fathom on my own. And let’s face it, sometimes
 the math in deep learning papers can look <a href="https://twitter.com/seluappendix" class="ei iy" rel="noopener nofollow">a lot like hieroglyphics</a>, except with no <a href="https://en.wikipedia.org/wiki/Rosetta_Stone" class="ei iy" rel="noopener nofollow">Rosetta Stone</a> to aid in translation.</p><p id="4889" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">But
 I think the journey we took here showed us that this knee-jerk response
 of feeling of intimidated, while wholly understandable, is by no means 
unavoidable. Although the Kaiming and (especially) the Xavier papers do 
contain their fair share of math, we saw firsthand how experiments, 
empirical observation, and some straightforward common sense were enough
 to help derive the core set of principals underpinning what is 
currently the most widely-used weight initialization scheme.</p><p id="c773" class="hz ia gg ib b ic it id ie if iu ig ih ii iv ij ik il iw im in io ix ip iq is fz hd" data-selectable-paragraph="">Alternately put: when in doubt, be courageous, try things out, and see what happens!</p></div></div></section></div></article><div class="yb fy fc mq v ye mv my" data-test-id="post-sidebar"><div class="n p"><div class="ao ap aq ar as at au v"><div class="mz n ah"><div class="ym"><div><div class="na nb s"><p class="ba b nc nd ne du nf">Written by</p><div class="ng nh s"><a href="https://medium.com/@jamesdell?source=post_sidebar--------------------------post_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><h2 class="ba jb dk bc gf hd fz">James Dellinger</h2></a></div><div class="ni s"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fuser%2F97c4870a6508%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_sidebar-97c4870a6508-------------------------follow_card-----------" class="ba b bb bc dy be dz ea eb ec ed bl bm bn ee ef br bs bt bu bv bw" rel="noopener">Follow</a></span></div></div><div class="nj nk nl n"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_sidebar-----954fb9b47c79---------------------clap_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv nw r nx ny"><svg width="29" height="29" aria-label="clap"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="og"><h4 class="ba b bb bc du"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">3.5K </button></h4></div></div></div></div><div class="nk s"><button class="ev ns ce"><div class="oj n o aw"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg><div class="s am ok ol om on oo op oq or"><h4 class="ba b bb bc du">23<!-- --> </h4></div></div></button></div><div class="hx"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_sidebar-----954fb9b47c79---------------------bookmark_sidebar-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div><div class="yb ym mq fc mr ms mt mu mv mw"></div><div><div class="os ki n ah p"><div class="n p"><div class="ao ap aq ar as gd au v"><div class="ot ou ov ow ox oy"><div class="oz s"><h2 class="ba jb jc je jf jg ji jj jk jm jn jo jq jr js ju jv hd">Sign up for The Daily Pick</h2></div><div class="pa s"><h3 class="ba b pb bc hd">By Towards Data Science</h3></div><div class="pc pd s"><p class="ba b pe pf pg ph pi pj pk pl pm pn hd">Hands-on
 real-world examples, research,  tutorials, and cutting-edge techniques 
delivered Monday to Thursday. Make learning your daily ritual.&nbsp;<a href="https://medium.com/towards-data-science/newsletters/the-daily-pick?source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------" class="ei ej bz ca cb cc cd ce cf bl cg em en iy" rel="noopener">Take a look</a></p></div><div class="n ct"><div class="n cq ah po"><div id="g-recaptcha"></div><div class="pp"><div class="pq n o ck pr ps cn co"><div class="wp s pu"><div class=""><div class="qm qg n o ah qk"><div class="am"><div class="qn s"><h4 class="ba b dk dl du"><input aria-label="email" class="pv pw px wq wr qa qb ws wt qe qf qg qh qi qj qk hd ql" pattern=".*" placeholder="Your email" type="text"></h4></div></div></div></div></div><div class="qo qp s hq qq"><div><button class="ba b dk dl dy qr dz ea eb ec ed bl bm bn ee ef br bs bt bu bv bw"><span class="hw" aria-hidden="true"><svg width="20" height="16" viewBox="0 0 20 16"><path d="M0 .35v15.3h20V.35H0zm6.95 9.38l3.05 2.5 3.05-2.5 4.88 4.73H2.07l4.88-4.73zM1.2 13.64V5.02l4.82 3.94-4.82 4.68zm12.78-4.68l4.82-3.94v8.62l-4.82-4.68zm4.82-7.42v1.94l-8.8 7.2-8.8-7.2V1.54h17.6z"></path></svg></span>Get this newsletter</button></div></div></div><div class="wu lq s pu"><h4 class="ba b qt nd hd">By signing up, you will create a Medium account if you don’t already have one. Review our <a href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------" class="ei ej bz ca cb cc cd ce cf bl cg em en iy" target="_blank" rel="noopener">Privacy Policy</a> for more information about our privacy practices.</h4></div></div><div class="qu qv aj"><h4 class="ba b bb bc hd"><b>Check your inbox</b><br>Medium sent you an email at  to complete your subscription.</h4></div></div></div></div><div class="n ct"></div><div class="n o ct"></div><div class="qw os s"><div class="qx n ck hu"><div class="n aw"><div class="qy s"><span class="s qz ra rb e d"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_actions_footer-----954fb9b47c79---------------------clap_footer-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv nw r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="am rc og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">3.5K<span class="s h g f rd re">&nbsp;</span></button><span class="s h g f rd re"></span></h4></div></div></div></span><span class="s h g f rd re"><div class="n cq"><div class="s am nm nn"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_actions_footer-----954fb9b47c79---------------------clap_footer-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv nw r nx ny"><svg width="33" height="33" viewBox="0 0 33 33" aria-label="clap"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></div></a></span></div><div class="s nz oa ob oc rf rg rh ri rj rk"><div class="am rc og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">3.5K<span class="s h g f rd re">&nbsp;</span></button><span class="s h g f rd re"></span></h4></div></div></div></span></div><div class="s rl rm rn ro rp"></div><button class="ev ns ce"><div class="oj n o aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><span class="rq s h g f rd re"><svg width="33" height="33" viewBox="0 0 33 33" fill="none" class="r" aria-label="responses"><path clip-rule="evenodd" d="M24.28 25.5l.32-.29c2.11-1.94 3.4-4.61 3.4-7.56C28 11.83 22.92 7 16.5 7S5 11.83 5 17.65s5.08 10.66 11.5 10.66c1.22 0 2.4-.18 3.5-.5l.5-.15.41.33a8.86 8.86 0 0 0 4.68 2.1 7.34 7.34 0 0 1-1.3-4.15v-.43zm1 .45c0 1.5.46 2.62 1.69 4.44.22.32.01.75-.38.75a9.69 9.69 0 0 1-6.31-2.37c-1.2.35-2.46.54-3.78.54C9.6 29.3 4 24.09 4 17.65 4 11.22 9.6 6 16.5 6S29 11.22 29 17.65c0 3.25-1.42 6.18-3.72 8.3z"></path></svg></span><span class="rr s qz ra rb e d"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></span></div></div><div class="s am rs ol rt on ru op rv rw rx ry"><h4 class="ba b bb bc hd">23<!-- --> </h4></div></div></button></div><div class="n o"><div class="hv s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="rz s db"><div class="hx"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=post_actions_footer--------------------------bookmark_footer-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div><div class="sa qx s"><ul class="ce cf"><li class="bv sb hw sc"><a href="https://towardsdatascience.com/tagged/deep-learning" class="ba b pb sd du se sf bw s lf">Deep Learning</a></li><li class="bv sb hw sc"><a href="https://towardsdatascience.com/tagged/neural-networks" class="ba b pb sd du se sf bw s lf">Neural Networks</a></li><li class="bv sb hw sc"><a href="https://towardsdatascience.com/tagged/weight-initialization" class="ba b pb sd du se sf bw s lf">Weight Initialization</a></li><li class="bv sb hw sc"><a href="https://towardsdatascience.com/tagged/towards-data-science" class="ba b pb sd du se sf bw s lf">Towards Data Science</a></li></ul></div></div></div><div><div class="n p"><div class="ao ap aq ar as gd au v"></div></div><div class="s hu"><div class="sg sh s ox"><div class="n p"><div class="ao ap aq ar as gd au v"><div class="n o ck"><h2 class="ba jb si pf sj jf sk ph sl jj sm pj sn jn so pl sp jr sq pn sr jv kp ss st su sv sw hd"><a href="https://towardsdatascience.com/?source=follow_footer-------------------------------------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener">More from Towards Data Science</a></h2><div class="bv" aria-hidden="false" aria-describedby="collectionFollowPopover" aria-labelledby="collectionFollowPopover"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F954fb9b47c79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer--------------------------follow_footer-----------" class="ba b bb bc dy be dz ea eb ec ed bl bm bn ee ef br bs bt bu bv bw" rel="noopener"><div class="n aw">Follow</div></a></span></div></div><div class="nh sx s"><h4 class="ba b bb bc du">A Medium publication sharing concepts, ideas, and codes.</h4></div></div></div></div></div><div class="sy s ox hu"><div class="n p"><div class="sz ta tb tc td te au v"><div class="fs ft aen s he hf aeo aep aeq"><div class="n p"><div class="ao ap aq ar as gd au v"><div class="v ko"><div class="s"><div class="o n"><div></div><div class="v n ct"><div class="n"><div style="flex: 1 1 0%;"><span class="ba b bb bc hd"><a href="https://medium.com/@nieberdingchris?source=follow_footer---------0----------------------------" class="" rel="noopener"><h4 class="ba b bb bc fj">Christoph Nieberding</h4></a></span></div></div><span class="ba b bb bc du"><a class="" rel="noopener" href="https://towardsdatascience.com/the-data-product-design-thinking-process-6b3eba561b2b?source=follow_footer---------0----------------------------"><h4 class="ba b bb bc du"><span class="hk">·</span>Apr 3, 2019</h4></a></span></div></div><div class="zw s"><div><div class="eq fa ya fw fx fy"></div><section class="fz ga gb dr gc"><div class=""><h1 id="2db1" class="ge gf gg ba gh aer id jf aes ig jj aet aeu aev aew aex aey aez afa afb zw hc hd"><a class="ei bw" rel="noopener" href="https://towardsdatascience.com/the-data-product-design-thinking-process-6b3eba561b2b?source=follow_footer---------0----------------------------">The Data Product Design Thinking Process</a></h1></div><div class=""><h2 id="e1a6" class="afc gf gg ba b afd afe aff ic je if ji jk jm jo jq js ju du">How to use Design Thinking for wicked data visualization problems.</h2></div><figure class="afg ki fs ft paragraph-image"><a href="https://towardsdatascience.com/the-data-product-design-thinking-process-6b3eba561b2b?source=follow_footer---------0----------------------------"><div class="afh fs ft"><div class="ks s am kt"><div class="afi kv s"><div class="fb kn eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ay yf" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Qm1tODZeypLsfPClZCdcQw_002.png" width="700" height="430"></div><img alt="Image for post" class="yb yc eq fe fa ko v c" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Qm1tODZeypLsfPClZCdcQw.png" srcset="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Qm1tODZeypLsfPClZCdcQw_005.png 276w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Qm1tODZeypLsfPClZCdcQw_004.png 552w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Qm1tODZeypLsfPClZCdcQw_003.png 640w, Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Qm1tODZeypLsfPClZCdcQw.png 700w" sizes="700px" width="700" height="430"><noscript></noscript></div></div></div></a></figure><p id="a210" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq cw is fz hd" data-selectable-paragraph="">Curiosity is a major driver for all of us. We are constantly carrying out research into processes, causes and effects.</p><p id="7c7b" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">We
 want to understand how companies, operational processes and economic 
relations work, what steps and parts they consist of, why things happen 
and how everything is interrelated.</p><p id="8c8a" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">Once we have analyzed everything, we can use this knowledge to exert influence on the world in a positive way.</p><p id="d18d" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">Data
 is an increasingly important factor in the search for correlations. The
 right data (smart data instead of big data) shed more light on the 
darkness. Without data, an accurate, systematic analysis and precise 
design of the world around us is no longer conceivable. …</p></section></div></div></div><div class="afk s"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/the-data-product-design-thinking-process-6b3eba561b2b?readmore=1&amp;source=follow_footer---------0----------------------------"><h4 class="ba b bb bc fj">Read more  · 6 min read</h4></a></div><div class="afl n o ck"><div class="n o"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F6b3eba561b2b&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer-----6b3eba561b2b----0-----------------clap_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">173 </button></h4></div></div></div><div class="afm n o afn vi afo afp afq"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/the-data-product-design-thinking-process-6b3eba561b2b?responsesOpen=true&amp;source=follow_footer---------0----------------------------"><button class="ev ns ce"><div class="afr n o aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="14" aria-labelledby="14"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></div></div><div class="s am rs afs rt aft ru afu rv afv rx afw"></div></div></button></a></div></div><div class="n o afx"><div class="eg s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="eg s"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="15" aria-labelledby="15"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F6b3eba561b2b&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer---------0-----------------bookmark_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="zk"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div></div></div><div class="fs ft aen s hn aga hp wi agb agc agd age agf agg"><div class="n p"><div class="ao ap aq ar as gd au v"><hr class="ns afy afz cf"><div class="v ko"><div class="ir s agh"><div class="o n"><div></div><div class="v n ct"><div class="n"><div style="flex: 1 1 0%;"><span class="ba b bb bc hd"><a href="https://medium.com/@srajan_61588?source=follow_footer---------1----------------------------" class="" rel="noopener"><h4 class="ba b bb bc fj">Sathy Rajasekharan</h4></a></span></div></div><span class="ba b bb bc du"><a class="" rel="noopener" href="https://towardsdatascience.com/how-ai-helps-mothers-in-kenya-get-the-care-they-need-faster-eb4f05b34732?source=follow_footer---------1----------------------------"><h4 class="ba b bb bc du"><span class="hk">·</span>Apr 3, 2019<svg class="zk agi agj" width="15" height="15" viewBox="0 0 15 15"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></h4></a></span></div></div><div class="zw s"><div><div class="eq fa ya fw fx fy"></div><section class="fz ga gb dr gc"><div class=""><h1 id="3b5a" class="ge gf gg ba gh aer id jf aes ig jj aet aeu aev aew aex aey aez afa afb zw hc hd"><a class="ei bw" rel="noopener" href="https://towardsdatascience.com/how-ai-helps-mothers-in-kenya-get-the-care-they-need-faster-eb4f05b34732?source=follow_footer---------1----------------------------">How AI helps mothers in Kenya get the care they need, faster</a></h1></div><p id="9ac2" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq agk is fz hd" data-selectable-paragraph="">Every mother has questions during and after a pregnancy. <em class="kz">How often should I feel my baby kick? When should I go to the hospital? How do I know if my newborn is feeding enough?</em>
 In many settings around the world, mothers get in touch with their 
providers, friends or search the internet for these answers. But what 
about a mother who only has a primary school education, living in a 
rural community in Kenya, whose connection to the outside world is 
simple feature phone?</p><figure class="cw ki fs ft paragraph-image"><a href="https://towardsdatascience.com/how-ai-helps-mothers-in-kenya-get-the-care-they-need-faster-eb4f05b34732?source=follow_footer---------1----------------------------"><div class="agl fs ft"><div class="ks s am kt"><div class="agm kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1rL51Rc9CoRoR5JuJi08gQw.jpeg" width="762" height="800"></div><img alt="Image for post" class="fb kn eq fe fa ko v c" width="762" height="800"><noscript></noscript></div></div></div></a></figure><p id="90df" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq cw is fz hd" data-selectable-paragraph=""><a href="http://jacarandahealth.org/" class="ei iy" rel="noopener nofollow">Jacaranda Health</a>
 is trying to find solutions to improve health outcomes for low-income 
mothers who seek care at public hospitals. We launched text messaging 
service called PROMPTS that provides pregnant women and new mothers with
 essential information. In a short period of time, over 11,000 mothers 
have signed up for the service. Our initial objective was to send a 
series of rigorously tested messages to the mothers to ‘prompt’ them to 
seek care. We soon realized that mothers have questions they want 
answered — lots of questions! Almost half of our users respond to the 
text prompts with three to five questions, and a small percentage have 
more than 20 questions. We set up a help-desk to answer these questions 
(via text message). Most of these questions are general in nature (<em class="kz">“can I eat avocados during pregnancy?”</em>), but at least 30 percent of our incoming questions could require an urgent response (<em class="kz">“I’m bleeding, what should I do?”</em>).
 As PROMPTS rapidly scales to hundreds of thousands of mothers across 
the country, we face an ethical challenge: how can we accurately answer 
thousands of questions and respond rapidly to urgent questions? …</p></section></div></div></div><div class="afk s"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/how-ai-helps-mothers-in-kenya-get-the-care-they-need-faster-eb4f05b34732?readmore=1&amp;source=follow_footer---------1----------------------------"><h4 class="ba b bb bc fj">Read more  · 4 min read</h4></a></div><div class="afl n o ck"><div class="n o"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2Feb4f05b34732&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer-----eb4f05b34732----1-----------------clap_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">74 </button></h4></div></div></div><div class="afm n o afn vi afo afp afq"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/how-ai-helps-mothers-in-kenya-get-the-care-they-need-faster-eb4f05b34732?responsesOpen=true&amp;source=follow_footer---------1----------------------------"><button class="ev ns ce"><div class="oj n o aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="16" aria-labelledby="16"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></div></div><div class="s am rs afs rt aft ru afu rv afv rx afw"><h4 class="ba b bb bc hd">1 </h4></div></div></button></a></div></div><div class="n o afx"><div class="eg s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="eg s"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="17" aria-labelledby="17"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2Feb4f05b34732&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer---------1-----------------bookmark_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="zk"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div></div></div><div class="fs ft aen s hn aga hp wi agb agc agd age agf agg"><div class="n p"><div class="ao ap aq ar as gd au v"><hr class="ns afy afz cf"><div class="v ko"><div class="ir s agh"><div class="o n"><div></div><div class="v n ct"><div class="n"><div style="flex: 1 1 0%;"><span class="ba b bb bc hd"><a href="https://medium.com/@kayo_gh?source=follow_footer---------2----------------------------" class="" rel="noopener"><h4 class="ba b bb bc fj">Kwadwo Agyapon-Ntra</h4></a></span></div></div><span class="ba b bb bc du"><a class="" rel="noopener" href="https://towardsdatascience.com/an-ai-story-part-3-python-notebooks-in-the-cloud-f7d4d62af1ae?source=follow_footer---------2----------------------------"><h4 class="ba b bb bc du"><span class="hk">·</span>Apr 3, 2019</h4></a></span></div></div><div class="zw s"><div><div class="eq fa ya fw fx fy"></div><section class="fz ga gb dr gc"><div class=""><h1 id="39ee" class="ge gf gg ba gh aer id jf aes ig jj aet aeu aev aew aex aey aez afa afb zw hc hd"><a class="ei bw" rel="noopener" href="https://towardsdatascience.com/an-ai-story-part-3-python-notebooks-in-the-cloud-f7d4d62af1ae?source=follow_footer---------2----------------------------">An AI Story — Part 3</a></h1></div><div class=""><h2 id="94d6" class="afc gf gg ba b afd afe aff ic je if ji jk jm jo jq js ju du">Python notebooks in the cloud</h2></div><figure class="afg ki fs ft paragraph-image"><a href="https://towardsdatascience.com/an-ai-story-part-3-python-notebooks-in-the-cloud-f7d4d62af1ae?source=follow_footer---------2----------------------------"><div class="afh fs ft"><div class="ks s am kt"><div class="agn kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0o-696rqHDAX31Hzq.jpg" width="700" height="438"></div><img alt="Image for post" class="fb kn eq fe fa ko v c" width="700" height="438"><noscript></noscript></div></div></div></a></figure><h2 id="841b" class="ago ja gg ba jb si agp pf jf sk agq ph jj sm agr pj jn so ags pl jr sq agt pn jv agu hd" data-selectable-paragraph="">Ashesi DSC</h2><p id="f25f" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq agv is fz hd" data-selectable-paragraph="">For
 six weeks, from February to March, I had to work on a React JS project 
almost full-time. I was working with two awesome brothers (Yannick and 
Osborne, pictured below) here at <a href="https://meltwater.org/" class="ei iy" rel="noopener nofollow">MEST</a>
 on a product to help bring out the best in Ghana’s high school 
education system. It’s still too early to give you details, but our 
pitch went well. Here are a few pictures:</p></section></div></div></div><div class="afk s"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/an-ai-story-part-3-python-notebooks-in-the-cloud-f7d4d62af1ae?readmore=1&amp;source=follow_footer---------2----------------------------"><h4 class="ba b bb bc fj">Read more  · 5 min read</h4></a></div><div class="afl n o ck"><div class="n o"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2Ff7d4d62af1ae&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer-----f7d4d62af1ae----2-----------------clap_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">89 </button></h4></div></div></div><div class="afm n o afn vi afo afp afq"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/an-ai-story-part-3-python-notebooks-in-the-cloud-f7d4d62af1ae?responsesOpen=true&amp;source=follow_footer---------2----------------------------"><button class="ev ns ce"><div class="oj n o aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="18" aria-labelledby="18"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></div></div><div class="s am rs afs rt aft ru afu rv afv rx afw"><h4 class="ba b bb bc hd">1 </h4></div></div></button></a></div></div><div class="n o afx"><div class="eg s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="eg s"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="19" aria-labelledby="19"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2Ff7d4d62af1ae&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer---------2-----------------bookmark_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="zk"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div></div></div><div class="fs ft aen s hn aga hp wi agb agc agd age agf agg"><div class="n p"><div class="ao ap aq ar as gd au v"><hr class="ns afy afz cf"><div class="v ko"><div class="ir s agh"><div class="o n"><div></div><div class="v n ct"><div class="n"><div style="flex: 1 1 0%;"><span class="ba b bb bc hd"><a href="https://medium.com/@StrikingLoo?source=follow_footer---------3----------------------------" class="" rel="noopener"><h4 class="ba b bb bc fj">Luciano Strika</h4></a></span></div></div><span class="ba b bb bc du"><a class="" rel="noopener" href="https://towardsdatascience.com/k-means-clustering-unsupervised-learning-for-recommender-systems-397d3790f90f?source=follow_footer---------3----------------------------"><h4 class="ba b bb bc du"><span class="hk">·</span>Apr 3, 2019</h4></a></span></div></div><div class="zw s"><div><div class="eq fa ya fw fx fy"></div><section class="fz ga gb dr gc"><div class=""><h1 id="b5f9" class="ge gf gg ba gh aer id jf aes ig jj aet aeu aev aew aex aey aez afa afb zw hc hd"><a class="ei bw" rel="noopener" href="https://towardsdatascience.com/k-means-clustering-unsupervised-learning-for-recommender-systems-397d3790f90f?source=follow_footer---------3----------------------------">K-Means Clustering: Unsupervised Learning for Recommender Systems</a></h1></div><figure class="cw ki fs ft paragraph-image"><a href="https://towardsdatascience.com/k-means-clustering-unsupervised-learning-for-recommender-systems-397d3790f90f?source=follow_footer---------3----------------------------"><div class="afh fs ft"><div class="ks s am kt"><div class="agw kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/10kll-_uSBtGkyr76i5HPQA.jpeg" width="700" height="360"></div><img alt="Image for post" class="fb kn eq fe fa ko v c" width="700" height="360"><noscript></noscript></div></div></div></a><figcaption class="lq lr fu fs ft ls lt ba b pb bc du" data-selectable-paragraph="">Your brain on Unsupervised Learning. Source: <a href="https://pixabay.com/illustrations/brain-mind-psychology-idea-hearts-2062048/" class="ei iy" rel="noopener nofollow">Pixabay</a>.</figcaption></figure><p id="b5a9" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq cw is fz hd" data-selectable-paragraph="">Unsupervised
 Learning has been called the closest thing we have to “actual” 
Artificial Intelligence, in the sense of General AI, with K-Means 
Clustering one of its simplest, but most powerful applications.</p><p id="d5e9" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">I
 am not here to discuss whether those claims are true or not, as I am 
not an expert nor a philosopher. I will however state, that I am often 
amazed by how well unsupervised learning techniques, even the most 
rudimentary, capture patterns in the data that I would expect only 
people to find.</p><p id="45bf" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">Today
 we’ll apply unsupervised learning on a Dataset I gathered myself. It’s a
 database of professional Magic: The Gathering decks that I crawled from
 <a href="https://mtgtop8.com/" class="ei iy" rel="noopener nofollow">mtgtop8.com,</a> …</p></section></div></div></div><div class="afk s"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/k-means-clustering-unsupervised-learning-for-recommender-systems-397d3790f90f?readmore=1&amp;source=follow_footer---------3----------------------------"><h4 class="ba b bb bc fj">Read more  · 8 min read</h4></a></div><div class="afl n o ck"><div class="n o"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F397d3790f90f&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer-----397d3790f90f----3-----------------clap_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">142 </button></h4></div></div></div><div class="afm n o afn vi afo afp afq"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/k-means-clustering-unsupervised-learning-for-recommender-systems-397d3790f90f?responsesOpen=true&amp;source=follow_footer---------3----------------------------"><button class="ev ns ce"><div class="oj n o aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="20" aria-labelledby="20"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></div></div><div class="s am rs afs rt aft ru afu rv afv rx afw"><h4 class="ba b bb bc hd">2 </h4></div></div></button></a></div></div><div class="n o afx"><div class="eg s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="eg s"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="21" aria-labelledby="21"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F397d3790f90f&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer---------3-----------------bookmark_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="zk"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div></div></div><div class="fs ft aen s hn aga hp wi agb agc agd age agf agg"><div class="n p"><div class="ao ap aq ar as gd au v"><hr class="ns afy afz cf"><div class="v ko"><div class="ir s agh"><div class="o n"><div></div><div class="v n ct"><div class="n"><div style="flex: 1 1 0%;"><span class="ba b bb bc hd"><a href="https://medium.com/@manunalepa?source=follow_footer---------4----------------------------" class="" rel="noopener"><h4 class="ba b bb bc fj">Manu NALEPA</h4></a></span></div></div><span class="ba b bb bc du"><a class="" rel="noopener" href="https://towardsdatascience.com/pandaral-lel-a-simple-and-efficient-tool-to-parallelize-your-pandas-operations-on-all-your-cpus-bb5ff2a409ae?source=follow_footer---------4----------------------------"><h4 class="ba b bb bc du"><span class="hk">·</span>Apr 2, 2019<svg class="zk agi agj" width="15" height="15" viewBox="0 0 15 15"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></h4></a></span></div></div><div class="zw s"><div><div class="eq fa ya fw fx fy"></div><section class="fz ga gb dr gc"><div class=""><h1 id="11a8" class="ge gf gg ba gh aer id jf aes ig jj aet aeu aev aew aex aey aez afa afb zw hc hd"><a class="ei bw" rel="noopener" href="https://towardsdatascience.com/pandaral-lel-a-simple-and-efficient-tool-to-parallelize-your-pandas-operations-on-all-your-cpus-bb5ff2a409ae?source=follow_footer---------4----------------------------">Pandarallel — A simple and efficient tool to parallelize your pandas computation on all your CPUs</a></h1></div><div class=""><h2 id="0d04" class="afc gf gg ba b afd afe aff ic je if ji jk jm jo jq js ju du">How to significantly speed up your pandas computation with only one line of code.</h2></div><p id="4372" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq agx is fz hd" data-selectable-paragraph="">Complete <strong class="ib gh">Pandaral·lel</strong> repository and documentation is available on this <a href="https://github.com/nalepae/pandarallel" class="ei iy" rel="noopener nofollow">GitHub page</a>.</p><p id="bba5" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">The library presented in this post is only supported on Linux &amp; MacOS.</p></section><div class="n p cw agy agz pc" role="separator"><span class="aha hh bv ahb ahc ahd"></span><span class="aha hh bv ahb ahc ahd"></span><span class="aha hh bv ahb ahc"></span></div><section class="fz ga gb dr gc"><h1 id="0e65" class="ahe ja gg ba jb jc je jf jg ji jj jk jm jn jo jq jr js ju jv os ahf hd" data-selectable-paragraph="">What issue does bother us?</h1><p id="6f04" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq ahg is fz hd" data-selectable-paragraph="">With <a href="https://github.com/pandas-dev/pandas" class="ei iy" rel="noopener nofollow">pandas</a>, when you run the following line:</p><figure class="cw ki"><div class="ks s am"><div class="ahh kv s"></div></div></figure><p id="4445" class="hz ia gg ib b ic ahi id ie if ahj ig ih ii jz ij ik il ka im in io kb ip iq is fz hd" data-selectable-paragraph="">You get this CPU usage:</p><figure class="cw ki fs ft paragraph-image"><a href="https://towardsdatascience.com/pandaral-lel-a-simple-and-efficient-tool-to-parallelize-your-pandas-operations-on-all-your-cpus-bb5ff2a409ae?source=follow_footer---------4----------------------------"><div class="ahk fs ft"><div class="ks s am kt"><div class="ahl kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img alt="Image for post" class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/172cCDhz-xyWJLZ7t1_NQJA.gif" width="699" height="159"></div><img alt="Image for post" class="fb kn eq fe fa ko v c" width="699" height="159"><noscript></noscript></div></div></div></a><figcaption class="lq lr fu fs ft ls lt ba b pb bc du" data-selectable-paragraph="">Standard Pandas apply — Only 1 CPU is used.</figcaption></figure><p id="89b4" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq cw is fz hd" data-selectable-paragraph="">Even if your computer has several CPUs, only one is fully dedicated to your calculation.</p><p id="2562" class="hz ia gg ib b ic id ie if ig ih ii ij ik il im in io ip iq afj is fz hd" data-selectable-paragraph="">Instead of this CPU usage, we would like <strong class="ib gh">a simple way</strong> to get something like this:</p></section></div></div></div><div class="afk s"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/pandaral-lel-a-simple-and-efficient-tool-to-parallelize-your-pandas-operations-on-all-your-cpus-bb5ff2a409ae?readmore=1&amp;source=follow_footer---------4----------------------------"><h4 class="ba b bb bc fj">Read more  · 3 min read</h4></a></div><div class="afl n o ck"><div class="n o"><div class="n o"><div class="s am nm nn no np nq"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2Fbb5ff2a409ae&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer-----bb5ff2a409ae----4-----------------clap_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><div class="ce nr ns nt ev nu nv wo r nx ny"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nz oa ob oc od oe of"><div class="og"><h4 class="ba b bb bc hd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en">1.6K </button></h4></div></div></div><div class="afm n o afn vi afo afp afq"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener" href="https://towardsdatascience.com/pandaral-lel-a-simple-and-efficient-tool-to-parallelize-your-pandas-operations-on-all-your-cpus-bb5ff2a409ae?responsesOpen=true&amp;source=follow_footer---------4----------------------------"><button class="ev ns ce"><div class="oj n o aw"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="22" aria-labelledby="22"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></div></div><div class="s am rs afs rt aft ru afu rv afv rx afw"><h4 class="ba b bb bc hd">8 </h4></div></div></button></a></div></div><div class="n o afx"><div class="eg s"><div class="bv" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="eg s"><div><div class="bv" role="tooltip" aria-hidden="false" aria-describedby="23" aria-labelledby="23"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2Fbb5ff2a409ae&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79&amp;source=follow_footer---------4-----------------bookmark_preview-----------" class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="zk"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div></div></div><div class="n p"><div class="ao ap aq ar as gd au v"><hr class="ns afy afz cf"></div></div><div class="tf os s"><div class="te s lr"><a href="https://towardsdatascience.com/?source=follow_footer-------------------------------------" class="ba b bb bc dy be dz ea eb ec ed bl bm bn ee ef br bs bt bu bv bw" rel="noopener">Read more from <!-- -->Towards Data Science</a></div></div></div></div></div><div class="s tg hu"><div class="n p"><div class="ao ap aq ar as at au v"><div class="th ir s"><div class="ti nb tj ir s tk tl"><h2 class="ba jb jc je jf jg ji jj jk jm jn jo jq jr js ju jv hd">More From Medium</h2></div><div class="cq n aw ct tm tn to tp tq tr ts tt tu tv tw tx ty tz ua"><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/being-a-cobol-developer-can-be-very-fun-c0072454d75c?source=post_internal_links---------0----------------------------">Being a COBOL developer can be very fun</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://luca-picci.medium.com/?source=post_internal_links---------0----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Luca Piccinelli</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------0----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/being-a-cobol-developer-can-be-very-fun-c0072454d75c?source=post_internal_links---------0----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0mk6Rc_ydMbO2RUZ9.jpg" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/0*mk6Rc_ydMbO2RUZ9" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*mk6Rc_ydMbO2RUZ9 48w, https://miro.medium.com/fit/c/140/140/0*mk6Rc_ydMbO2RUZ9 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa?source=post_internal_links---------1----------------------------">9 Distance Measures in Data Science</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://medium.com/@maartengrootendorst?source=post_internal_links---------1----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Maarten Grootendorst</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------1----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa?source=post_internal_links---------1----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/12J3iaDnuLhonNGvlTKthiQ.png" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/1*2J3iaDnuLhonNGvlTKthiQ.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*2J3iaDnuLhonNGvlTKthiQ.png 48w, https://miro.medium.com/fit/c/140/140/1*2J3iaDnuLhonNGvlTKthiQ.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/excel-vs-python-how-to-do-common-data-analysis-tasks-54f1bdd6dfaa?source=post_internal_links---------2----------------------------">Excel vs Python: How to do Common Data Analysis Tasks</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://pooja-rane1194.medium.com/?source=post_internal_links---------2----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Pooja Rane</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------2----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/excel-vs-python-how-to-do-common-data-analysis-tasks-54f1bdd6dfaa?source=post_internal_links---------2----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Sj76gx1iy30Kq2mTEIL-jg.jpeg" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/1*Sj76gx1iy30Kq2mTEIL-jg.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*Sj76gx1iy30Kq2mTEIL-jg.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*Sj76gx1iy30Kq2mTEIL-jg.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/how-to-extract-the-text-from-pdfs-using-python-and-the-google-cloud-vision-api-7a0a798adc13?source=post_internal_links---------3----------------------------">How to Extract the Text from PDFs Using Python and the Google Cloud Vision API</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://szeamer.medium.com/?source=post_internal_links---------3----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Silvia Zeamer</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------3----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/how-to-extract-the-text-from-pdfs-using-python-and-the-google-cloud-vision-api-7a0a798adc13?source=post_internal_links---------3----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1LXEzOG6snVtCtYszzg8N4g.jpeg" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/1*LXEzOG6snVtCtYszzg8N4g.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*LXEzOG6snVtCtYszzg8N4g.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*LXEzOG6snVtCtYszzg8N4g.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/from-text-to-knowledge-the-information-extraction-pipeline-b65e7e30273e?source=post_internal_links---------4----------------------------">From text to knowledge. The information extraction pipeline</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://bratanic-tomaz.medium.com/?source=post_internal_links---------4----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Tomaz Bratanic</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------4----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/from-text-to-knowledge-the-information-extraction-pipeline-b65e7e30273e?source=post_internal_links---------4----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1ymxq_lqn1KFWwhbzsT4k8w.png" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/1*ymxq_lqn1KFWwhbzsT4k8w.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*ymxq_lqn1KFWwhbzsT4k8w.png 48w, https://miro.medium.com/fit/c/140/140/1*ymxq_lqn1KFWwhbzsT4k8w.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/git-commands-cheat-sheet-software-developer-54f6aedc1c46?source=post_internal_links---------5----------------------------">18 Git Commands I Learned During My First Year as a Software Developer</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://ahmad-abdullah.medium.com/?source=post_internal_links---------5----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Ahmad Abdullah</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------5----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/git-commands-cheat-sheet-software-developer-54f6aedc1c46?source=post_internal_links---------5----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1iI5iT11GfqXGa1j7hcPOPA.jpeg" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/focal/140/140/47/50/1*iI5iT11GfqXGa1j7hcPOPA.jpeg" width="70" height="70" srcSet="https://miro.medium.com/focal/96/140/47/50/1*iI5iT11GfqXGa1j7hcPOPA.jpeg 48w, https://miro.medium.com/focal/140/140/47/50/1*iI5iT11GfqXGa1j7hcPOPA.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/deepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312?source=post_internal_links---------6----------------------------">Deepmind releases a new State-Of-The-Art Image Classification model — NFNets</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://mostafaosama18.medium.com/?source=post_internal_links---------6----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Mostafa Ibrahim</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------6----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/deepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312?source=post_internal_links---------6----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/0kyCODwc_4YLbm7mS.jpg" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/0*kyCODwc_4YLbm7mS" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*kyCODwc_4YLbm7mS 48w, https://miro.medium.com/fit/c/140/140/0*kyCODwc_4YLbm7mS 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv"><div class="uw ux s"><div class="v ko"><div class="n ck"><div class="s uy uz va vb"><div class="vc s"><h2 class="ba jb si pf jf sk ph jj pi vd jn pk ve jr pm vf jv hd"><a rel="noopener" href="https://towardsdatascience.com/5-data-science-programming-languages-not-including-python-or-r-3ad111134771?source=post_internal_links---------7----------------------------">5 Data Science Programming Languages Not Including Python or R</a></h2></div><div class="o n"><div></div><div class="v s"><div class="n"><div style="flex:1"><span class="ba b bb bc hd"><div class="cr n o vg"><span class="ba b pb bc hd"><a href="https://saraametwalli.medium.com/?source=post_internal_links---------7----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Sara A. Metwalli</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------7----------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg em en" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="eo hw s vi vj"><a class="ei ej bz ca cb cc cd ce cf bl ek el cg em en s" rel="noopener" href="https://towardsdatascience.com/5-data-science-programming-languages-not-including-python-or-r-3ad111134771?source=post_internal_links---------7----------------------------"><div class="ks s am kt"><div class="vk kv s"><div class="yb yc eq fe fa ko v kp kq kr"><img class="eq fe fa ko v kw kx ky" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/00DxkIBPiL3Kckzrc.jpg" role="presentation" width="70" height="70"></div><img class="fb kn vl vm vn vo vp vq vr vs vt vu c" role="presentation" width="70" height="70"><noscript><img class="vl vm vn vo vp vq vr vs vt vu" src="https://miro.medium.com/fit/c/140/140/0*0DxkIBPiL3Kckzrc" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*0DxkIBPiL3Kckzrc 48w, https://miro.medium.com/fit/c/140/140/0*0DxkIBPiL3Kckzrc 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="vv s vw vx"><div class="n p"><div class="ao ap aq ar as at au v"><div class="n ah"><div class="n o ck"><a href="https://medium.com/?source=post_page-----954fb9b47c79--------------------------------" class="ei ej bz ca cb cc cd ce cf bl vy vz cg wa wb" rel="noopener"><svg viewBox="0 0 3940 610" class="dz wc"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><h4 class="ba b bb bc wd"><div class="pd we n ck wf cm"><h4 class="ba b dk dl wg"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----954fb9b47c79--------------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg wa wb" rel="noopener">About</a></h4><h4 class="ba b dk dl wg"><a href="https://help.medium.com/hc/en-us?source=post_page-----954fb9b47c79--------------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg wa wb" rel="noopener">Help</a></h4><h4 class="ba b dk dl wg"><a href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----954fb9b47c79--------------------------------" class="ei ej bz ca cb cc cd ce cf bl vh cg wa wb" rel="noopener">Legal</a></h4></div></h4></div><div class="aj wh wi cm"><h4 class="ba b dk dl wd">Get the Medium app</h4></div><div class="aj wh wj cm wk"><div class="az s"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----954fb9b47c79--------------------------------" class="ei ej bz ca cb cc cd ce cf bl vy vz cg wa wb" rel="noopener nofollow"><img alt="A button that says 'Download on the App Store', and if clicked it will lead you to the iOS App store" class="" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41"></a></div><div class="s"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----954fb9b47c79--------------------------------" class="ei ej bz ca cb cc cd ce cf bl vy vz cg wa wb" rel="noopener nofollow"><img alt="A button that says 'Get it on, Google Play', and if clicked it will lead you to the Google Play store" class="" src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1W_RAPQ62h0em559zluJLdQ.png" width="135" height="41"></a></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__ = "main-20210216-161250-faa369b4bb"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"auroraPage":{"isAuroraPageEnabled":true},"bookReader":{"reader":{"currentAsset":null}},"cache":{"experimentGroupSet":true,"group":"control","tags":[],"serverVariantState":""},"client":{"isBot":false,"isEu":true,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"inAppBrowserName":"","routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"supportsWebp":true},"config":{"nodeEnv":"production","version":"main-20210216-161250-faa369b4bb","isTaggedVersion":false,"target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20210216-161250-faa369b4bb"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"main-20210216-161250-faa369b4bb","commit":"faa369b4bb6ad9cab536917fdc96bfd56b5d34a3"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e","9dc80918cc93","8a9336e5bb4","cef6983b292","54c98c43354d","193b68bd4fba","b7e45b22fec3","55760f21cdc5"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","errorTracking":"none"},"debug":{"requestId":"db3a5c6b-cf51-48a9-ae80-f819cbfba3ad","branchDeployConfig":null,"originalSpanCarrier":{"ot-tracer-spanid":"708ce4cd4d619e98","ot-tracer-traceid":"ab2370dd1adbce3","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79","host":"towardsdatascience.com","hostname":"towardsdatascience.com","susiModal":{"step":null,"operation":"register"},"postRead":false},"session":{"user":{"id":"lo_ec18ad8c2f94"},"xsrf":"","isSpoofed":false},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"Visitor:lo_ec18ad8c2f94":{"id":"lo_ec18ad8c2f94","__typename":"Visitor"},"ROOT_QUERY":{"__typename":"Query","visitor":{"__ref":"Visitor:lo_ec18ad8c2f94"},"viewer":null,"variantFlags":[{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"android_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"assign_default_topic_to_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"bane_add_user","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bane_verify_domain","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"branch_seo_metadata","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"default_seo_post_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"digest_delivery_window_one_hour_before","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_android_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_resume_reading_toast","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_mobile_featured_chunk","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_post_recommended_from_friends_provider","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_local_currency","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_parse_expires_at","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_failure","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_about_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_general_admission","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_sticky_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_tag_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_autotier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automated_mission_control_triggers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_text_me_the_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding_fonts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cleansweep_double_writes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_client_error_tracking","valueType":{"__typename":"VariantFlagString","value":"none"}},{"__typename":"VariantFlag","name":"enable_confirm_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cta_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_curation_priority_queue_experiment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_custom_domain_v2_settings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_dedicated_series_tab_api_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_feature_logging","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_referred_follow_cta","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_earn_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_edit_alt_text","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_to_subscribers_after_publish","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_embedding_based_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_end_of_post_cleanup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_evhead_com_to_ev_medium_com_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expanded_feature_chunk_pool","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_by_resend_rules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_expire_processor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_fyf_authors_and_collections","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_global_susi_modal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook_subscription_cancelled","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_highlander_member_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_hightower_user_minimum_guarantee","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_homepage_who_to_follow_module","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_homepage_write_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_increased_digest_timeout","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_post_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_json_logs_trained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_app_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_daily_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_notifications","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pay_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_cd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_publish_to_profile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_stories","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_threaded_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_unread_notification_count_mutation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_login_code_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_media_resource_try_catch","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_remove_section_a","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_miro_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mission_control","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_checkout_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_collaborative_filtering_data","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_login_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_three_dot_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_parsely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_patronus_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_popularity_feature","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_page_nav_stickiness_removal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_primary_topic_for_mobile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_design_reminder","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_page_seo_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_publish_to_email_for_publication_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_receipt_notes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_edit_and_delete","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_moderation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_follow_feed_cache","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rtr_channel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_s3_sites","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_save_to_medium","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace_ranker_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipalti_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trending_posts_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_predictions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trumpland_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_unfiltered_cf","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_untruncated_author_post_as_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound"}},{"__typename":"VariantFlag","name":"google_sign_in_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_generic_home_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_iceland_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_pub_follow_email_opt_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"is_not_medium_subscriber","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_fastrak","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_stripe_express","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"make_nav_sticky","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"new_transition_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"provider_for_credit_card_form","valueType":{"__typename":"VariantFlagString","value":"BRAINTREE"}},{"__typename":"VariantFlag","name":"pub_sidebar","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefine_average_post_reading_time","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"remove_post_post_similarity","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"retrained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sign_up_with_email_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"suppress_apple_missing_expires_date_alert","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"use_new_admin_topic_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"meterPost({\"postId\":\"954fb9b47c79\",\"postMeteringOptions\":{}})":{"__ref":"MeteringInfo:{}"},"postResult({\"id\":\"954fb9b47c79\"})":{"__ref":"Post:954fb9b47c79"}},"MeteringInfo:{}":{"__typename":"MeteringInfo","postIds":[],"maxUnlockCount":3,"unlocksRemaining":3},"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png":{"id":"1*ChFMdf--f5jbm-AYv6VdYA@2x.png","__typename":"ImageMetadata"},"CustomStyleSheet:7d00fb9fecc6":{"id":"7d00fb9fecc6","__typename":"CustomStyleSheet","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}},"header":{"__typename":"HeaderStyles","backgroundColor":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"rgb":"355876","alpha":"ff"},"postBackgroundColor":null,"backgroundImage":null,"headerScale":"HEADER_SCALE_MEDIUM","horizontalAlignment":"START","backgroundImageDisplayMode":"IMAGE_DISPLAY_MODE_FILL","backgroundImageVerticalAlignment":"START","backgroundColorDisplayMode":"COLOR_DISPLAY_MODE_SOLID","secondaryBackgroundColor":null,"nameColor":null,"nameTreatment":"NAME_TREATMENT_LOGO","postNameTreatment":"NAME_TREATMENT_LOGO","logoImage":{"__ref":"ImageMetadata:1*AGyTPCaRzVqL77kFwUwHKg.png"},"logoScale":"HEADER_SCALE_MEDIUM","taglineColor":{"__typename":"ColorValue","rgb":"ffffff","alpha":"ff"},"taglineTreatment":"TAGLINE_TREATMENT_HEADER"},"navigation":{"__typename":"HeaderNavigation","navItems":[{"__typename":"HeaderNavigationItem","name":"Editors' Picks","href":null,"tagSlugs":["editors-pick"],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Features","href":null,"tagSlugs":["tds-features"],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Explore","href":null,"tagSlugs":["tds-explore"],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Contribute","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fquestions-96667b06af5","tagSlugs":[],"type":"NAV_TYPE_LINK"}]},"postBody":null},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","__typename":"ImageMetadata","originalWidth":337,"originalHeight":122},"User:895063a310f4":{"id":"895063a310f4","__typename":"User","name":"Ludovic Benistant"},"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png":{"id":"1*hVxgUA6kP-PgL5TJjuyePg.png","__typename":"ImageMetadata"},"NewsletterV3:d6fe9076899":{"id":"d6fe9076899","__typename":"NewsletterV3","slug":"the-daily-pick","isSubscribed":false,"showPromo":true,"name":"The Daily Pick","description":"Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.","type":"NEWSLETTER_TYPE_COLLECTION","user":{"__ref":"User:895063a310f4"},"collection":{"__ref":"Collection:7f60cf5620c9"}},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","__typename":"Collection","domain":"towardsdatascience.com","googleAnalyticsId":null,"slug":"towards-data-science","colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraVisible":true,"favicon":{"__ref":"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png"},"name":"Towards Data Science","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"customStyleSheet":{"__ref":"CustomStyleSheet:7d00fb9fecc6"},"tagline":"A Medium publication sharing concepts, ideas, and codes.","isAuroraEligible":true,"viewerIsEditor":false,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"navItems":[{"__typename":"NavItem","title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"★","url":"https:\u002F\u002Ftowardsdatascience.com\u002Feditors-picks\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM"}],"creator":{"__ref":"User:895063a310f4"},"subscriberCount":551523,"avatar":{"__ref":"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png"},"isEnrolledInHightower":false,"newsletterV3":{"__ref":"NewsletterV3:d6fe9076899"},"viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":true,"isUserSubscribedToCollectionEmails":false,"viewerIsMuting":false,"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"description":"A Medium publication sharing concepts, ideas, and codes.","ampEnabled":false,"twitterUsername":"TDataScience","facebookPageId":null},"User:97c4870a6508":{"id":"97c4870a6508","__typename":"User","isFollowing":null,"viewerIsUser":false,"isSuspended":false,"name":"James Dellinger","hasCompletedProfile":false,"bio":"","imageId":"1*VWdH331WvzjQpoZxCJoqFA.jpeg","customStyleSheet":null,"customDomainState":null,"username":"jamesdell","isAuroraVisible":true,"socialStats":{"__typename":"SocialStats","followerCount":415},"isBlocking":null,"mediumMemberAt":0,"hasSubdomain":false,"isMuting":null,"allowNotes":true,"newsletterV3":null,"twitterScreenName":"jamrdell","isPartnerProgramEnrolled":false},"ImageMetadata:1*AGyTPCaRzVqL77kFwUwHKg.png":{"id":"1*AGyTPCaRzVqL77kFwUwHKg.png","__typename":"ImageMetadata","originalWidth":1376,"originalHeight":429},"Topic:1eca0103fff3":{"id":"1eca0103fff3","__typename":"Topic","name":"Machine Learning","slug":"machine-learning","isFollowing":null},"Paragraph:74b5e907e58e_0":{"id":"74b5e907e58e_0","__typename":"Paragraph","name":"18f9","text":"Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_1":{"id":"74b5e907e58e_1","__typename":"Paragraph","name":"4960","text":"I’d like to invite you to join me on an exploration through different approaches to initializing layer weights in neural networks. Step-by-step, through various short experiments and thought exercises, we’ll discover why adequate weight initialization is so important in training deep neural nets. Along the way we’ll cover various approaches that researchers have proposed over the years, and finally drill down on what works best for the contemporary network architectures that you’re most likely to be working with.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_2":{"id":"74b5e907e58e_2","__typename":"Paragraph","name":"5721","text":"The examples to follow come from my own re-implementation of a set of notebooks that Jeremy Howard covered in the latest version of fast.ai’s Deep Learning Part II course, currently being held this spring, 2019, at USF’s Data Institute.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":40,"end":57,"type":"A","href":"https:\u002F\u002Fnbviewer.jupyter.org\u002Fgithub\u002Fjamesdellinger\u002Ffastai_deep_learning_course_part2_v3\u002Fblob\u002Fmaster\u002F02_fully_connected_my_reimplementation.ipynb?flush_cache=true","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":85,"end":98,"type":"A","href":"https:\u002F\u002Fwww.usfca.edu\u002Ffaculty\u002Fjeremy-howard","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":114,"end":128,"type":"A","href":"https:\u002F\u002Fwww.fast.ai\u002F2019\u002F03\u002F06\u002Ffastai-swift\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":182,"end":235,"type":"A","href":"https:\u002F\u002Fwww.usfca.edu\u002Fdata-institute\u002Fcertificates\u002Fdeep-learning-part-two","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_3":{"id":"74b5e907e58e_3","__typename":"Paragraph","name":"a36f","text":"Why Initialize Weights","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_4":{"id":"74b5e907e58e_4","__typename":"Paragraph","name":"f4a5","text":"The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network. If either occurs, loss gradients will either be too large or too small to flow backwards beneficially, and the network will take longer to converge, if it is even able to do so at all.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_5":{"id":"74b5e907e58e_5","__typename":"Paragraph","name":"d79e","text":"Matrix multiplication is the essential math operation of a neural network. In deep neural nets with several layers, one forward pass simply entails performing consecutive matrix multiplications at each layer, between that layer’s inputs and weight matrix. The product of this multiplication at one layer becomes the inputs of the subsequent layer, and so on and so forth.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_6":{"id":"74b5e907e58e_6","__typename":"Paragraph","name":"a600","text":"For a quick-and-dirty example that illustrates this, let’s pretend that we have a vector x that contains some network inputs. It’s standard practice when training neural networks to ensure that our inputs’ values are scaled such that they fall inside such a normal distribution with a mean of 0 and a standard deviation of 1.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":89,"end":90,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_7":{"id":"74b5e907e58e_7","__typename":"Paragraph","name":"b0c9","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ne6gE3vogzJp53lwAYxtGw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_8":{"id":"74b5e907e58e_8","__typename":"Paragraph","name":"f011","text":"Let’s also pretend that we have a simple 100-layer network with no activations , and that each layer has a matrix a that contains the layer’s weights. In order to complete a single forward pass we’ll have to perform a matrix multiplication between layer inputs and weights at each of the hundred layers, which will make for a grand total of 100 consecutive matrix multiplications.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":114,"end":115,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":341,"end":344,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_9":{"id":"74b5e907e58e_9","__typename":"Paragraph","name":"efc6","text":"It turns out that initializing the values of layer weights from the same standard normal distribution to which we scaled our inputs is never a good idea. To see why, we can simulate a forward pass through our hypothetical network.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_10":{"id":"74b5e907e58e_10","__typename":"Paragraph","name":"e118","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*IK15xc15E1LJGlDP1FEXFA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_11":{"id":"74b5e907e58e_11","__typename":"Paragraph","name":"6f3f","text":"Whoa! Somewhere during those 100 multiplications, the layer outputs got so big that even the computer wasn’t able to recognize their standard deviation and mean as numbers. We can actually see exactly how long that took to happen.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_12":{"id":"74b5e907e58e_12","__typename":"Paragraph","name":"5afa","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*_yr6lnXY-1aXVUWb1MJIYA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_13":{"id":"74b5e907e58e_13","__typename":"Paragraph","name":"0ba2","text":"The activation outputs exploded within 29 of our network’s layers. We clearly initialized our weights to be too large.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_14":{"id":"74b5e907e58e_14","__typename":"Paragraph","name":"ab92","text":"Unfortunately, we also have to worry about preventing layer outputs from vanishing. To see what happens when we initialize network weights to be too small — we’ll scale our weight values such that, while they still fall inside a normal distribution with a mean of 0, they have a standard deviation of 0.01.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_15":{"id":"74b5e907e58e_15","__typename":"Paragraph","name":"4163","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*z89-cC4jCGPOkp3cnbyr8A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_16":{"id":"74b5e907e58e_16","__typename":"Paragraph","name":"6271","text":"During the course of the above hypothetical forward pass, the activation outputs completely vanished.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_17":{"id":"74b5e907e58e_17","__typename":"Paragraph","name":"08c0","text":"To sum it up, if weights are initialized too large, the network won’t learn well. The same happens when weights are initialized too small.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_18":{"id":"74b5e907e58e_18","__typename":"Paragraph","name":"da92","text":"How can we find the sweet spot?","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_19":{"id":"74b5e907e58e_19","__typename":"Paragraph","name":"7698","text":"Remember that as mentioned above, the math required to complete a forward pass through a neural network entails nothing more than a succession of matrix multiplications. If we have an output y that is the product of a matrix multiplication between our input vector x and weight matrix a, each element i in y is defined as","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":191,"end":192,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":265,"end":266,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":285,"end":286,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":306,"end":307,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":301,"end":302,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_20":{"id":"74b5e907e58e_20","__typename":"Paragraph","name":"2429","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*K3AIFVUelCr0z646zrQjPw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_21":{"id":"74b5e907e58e_21","__typename":"Paragraph","name":"15e5","text":"where i is a given row-index of weight matrix a, k is both a given column-index in weight matrix a and element-index in input vector x, and n is the range or total number of elements in x. This can also be defined in Python as:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":46,"end":47,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":97,"end":98,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":133,"end":134,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":186,"end":187,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":6,"end":7,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":49,"end":50,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":140,"end":141,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_22":{"id":"74b5e907e58e_22","__typename":"Paragraph","name":"316e","text":"y[i] = sum([c*d for c,d in zip(a[i], x)])","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_23":{"id":"74b5e907e58e_23","__typename":"Paragraph","name":"d276","text":"We can demonstrate that at a given layer, the matrix product of our inputs x and weight matrix a that we initialized from a standard normal distribution will, on average, have a standard deviation very close to the square root of the number of input connections, which in our example is √512.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":75,"end":76,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":95,"end":96,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_24":{"id":"74b5e907e58e_24","__typename":"Paragraph","name":"f5d3","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*oJDRa2HOPhe5JV7co5Ig-A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_25":{"id":"74b5e907e58e_25","__typename":"Paragraph","name":"6b2f","text":"This property isn’t surprising if we view it in terms of how matrix multiplication is defined: in order to calculate y we sum 512 products of the element-wise multiplication of one element of the inputs x by one column of the weights a. In our example where both x and a are initialized using standard normal distributions, each of these 512 products would have a mean of 0 and standard deviation of 1.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":117,"end":118,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":203,"end":204,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":234,"end":235,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":263,"end":264,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":269,"end":270,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_26":{"id":"74b5e907e58e_26","__typename":"Paragraph","name":"acb3","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*wMTdWrSPOXh8C6XxoSO7pg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_27":{"id":"74b5e907e58e_27","__typename":"Paragraph","name":"0a28","text":"It then follows that the sum of these 512 products would have a mean of 0, variance of 512, and therefore a standard deviation of √512.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":25,"end":28,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_28":{"id":"74b5e907e58e_28","__typename":"Paragraph","name":"b501","text":"And this is why in our example above we saw our layer outputs exploding after 29 consecutive matrix multiplications. In the case of our bare-bones 100-layer network architecture, what we’d like is for each layer’s outputs to have a standard deviation of about 1. This conceivably would allow us to repeat matrix multiplications across as many network layers as we want, without activations exploding or vanishing.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_29":{"id":"74b5e907e58e_29","__typename":"Paragraph","name":"95b6","text":"If we first scale the weight matrix a by dividing all its randomly chosen values by √512, the element-wise multiplication that fills in one element of the outputs y would now, on average, have a variance of only 1\u002F√512.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":36,"end":37,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":163,"end":164,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_30":{"id":"74b5e907e58e_30","__typename":"Paragraph","name":"8e87","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*qDpw22Z8XSDZe5MLLOLUew.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_31":{"id":"74b5e907e58e_31","__typename":"Paragraph","name":"ac76","text":"This means that the standard deviation of the matrix y, which contains each of the 512 values that are generated by way of the matrix multiplication between inputs x and weights a, would be 1. Let’s confirm this experimentally.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":53,"end":54,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":164,"end":165,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":178,"end":179,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_32":{"id":"74b5e907e58e_32","__typename":"Paragraph","name":"f3ed","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*5LAW2b1nDhPB9k7gt68yZg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_33":{"id":"74b5e907e58e_33","__typename":"Paragraph","name":"a5c0","text":"Now let’s re-run our quick-and-dirty 100-layer network. As before, we first choose layer weights at random from standard normal distribution inside [-1,1], but this time we scale those weights by 1\u002F√n, where n is the number of network input connections at a layer, which is 512 in our example.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":199,"end":200,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":208,"end":209,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_34":{"id":"74b5e907e58e_34","__typename":"Paragraph","name":"2d92","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*8-f9bmfeVVWwLLqSoQADSA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_35":{"id":"74b5e907e58e_35","__typename":"Paragraph","name":"b143","text":"Success! Our layer outputs neither exploded nor vanished, even after 100 of our hypothetical layers.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_36":{"id":"74b5e907e58e_36","__typename":"Paragraph","name":"57e4","text":"While at first glance it may seem like at this point we can call it a day, real-world neural networks aren’t quite as simple as our first example may seem to indicate. For the sake of simplicity, activation functions were omitted. However, we’d never do this in real life. It’s thanks to the placement of these non-linear activation functions at the tail end of network layers, that deep neural nets are able create close approximations of intricate functions that describe real-world phenomena, which can then be used to generate astoundingly impressive predictions, such as the classification of handwriting samples.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_37":{"id":"74b5e907e58e_37","__typename":"Paragraph","name":"169e","text":"Xavier Initialization","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_38":{"id":"74b5e907e58e_38","__typename":"Paragraph","name":"3231","text":"Up until a few years ago, most commonly used activation functions were symmetric about a given value, and had ranges that asymptotically approached values that were plus\u002Fminus a certain distance from this midpoint. The hyperbolic tangent and softsign functions exemplify this class of activations.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_39":{"id":"74b5e907e58e_39","__typename":"Paragraph","name":"839f","text":"Tanh and softsign activation functions. Credit: Sefik Ilkin Serengil’s blog.","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*39Dm-zzV98YO-WKCfXgeVg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":71,"end":76,"type":"A","href":"https:\u002F\u002Fsefiks.com\u002F2017\u002F11\u002F10\u002Fsoftsign-as-a-neural-networks-activation-function\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_40":{"id":"74b5e907e58e_40","__typename":"Paragraph","name":"5a52","text":"We’ll add a hyperbolic tangent activation function after each layer our hypothetical 100-layer network, and then see what happens when we use our home-grown weight initialization scheme where layer weights are scaled by 1\u002F√n.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":223,"end":225,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_41":{"id":"74b5e907e58e_41","__typename":"Paragraph","name":"b29e","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*5Ko4_sp9-58wK_hFL2GCHQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_42":{"id":"74b5e907e58e_42","__typename":"Paragraph","name":"d3a0","text":"The standard deviation of activation outputs of the 100th layer is down to about 0.06. This is definitely on the small side, but at least activations haven’t totally vanished!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_43":{"id":"74b5e907e58e_43","__typename":"Paragraph","name":"fafa","text":"As intuitive as the journey to discovering our home-grown weight init strategy may now seem in retrospect, you may be surprised to hear that as recently as 2010, this was not the conventional approach for initializing weight layers.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_44":{"id":"74b5e907e58e_44","__typename":"Paragraph","name":"04d8","text":"When Xavier Glorot and Yoshua Bengio published their landmark paper titled Understanding the difficulty of training deep feedforward neural networks, the “commonly used heuristic” to which they compared their experiments was that of initializing weights from a uniform distribution in [-1,1] and then scaling by 1\u002F√n.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":75,"end":148,"type":"A","href":"http:\u002F\u002Fproceedings.mlr.press\u002Fv9\u002Fglorot10a\u002Fglorot10a.pdf","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":75,"end":148,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":261,"end":268,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":315,"end":316,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_45":{"id":"74b5e907e58e_45","__typename":"Paragraph","name":"7aad","text":"It turns out this “standard” approach doesn’t actually work that well.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_46":{"id":"74b5e907e58e_46","__typename":"Paragraph","name":"6a48","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*RJ2AxAObnSszBlJ6_LZKrQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_47":{"id":"74b5e907e58e_47","__typename":"Paragraph","name":"33ac","text":"Re-running our 100-layer tanh network with “standard” weight initialization caused activation gradients to become infinitesimally small — they’re just about as good as vanished.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_48":{"id":"74b5e907e58e_48","__typename":"Paragraph","name":"43db","text":"This poor performance is actually what spurred Glorot and Bengio to propose their own weight initialization strategy, which they referred to as “normalized initialization” in their paper, and which is now popularly termed “Xavier initialization.”","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_49":{"id":"74b5e907e58e_49","__typename":"Paragraph","name":"54ed","text":"Xavier initialization sets a layer’s weights to values chosen from a random uniform distribution that’s bounded between","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_50":{"id":"74b5e907e58e_50","__typename":"Paragraph","name":"3192","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*H6t3yYBLlinNRUwmL-d7vw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_51":{"id":"74b5e907e58e_51","__typename":"Paragraph","name":"9c07","text":"where nᵢ is the number of incoming network connections, or “fan-in,” to the layer, and nᵢ₊₁ is the number of outgoing network connections from that layer, also known as the “fan-out.”","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":6,"end":8,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":87,"end":91,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_52":{"id":"74b5e907e58e_52","__typename":"Paragraph","name":"9fb4","text":"Glorot and Bengio believed that Xavier weight initialization would maintain the variance of activations and back-propagated gradients all the way up or down the layers of a network. In their experiments they observed that Xavier initialization enabled a 5-layer network to maintain near identical variances of its weight gradients across layers.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_53":{"id":"74b5e907e58e_53","__typename":"Paragraph","name":"3291","text":"With Xavier init. Credit: Glorot & Bengio.","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Gelf2ZcKYowsLf5FT4n0BQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":26,"end":41,"type":"A","href":"http:\u002F\u002Fproceedings.mlr.press\u002Fv9\u002Fglorot10a\u002Fglorot10a.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_54":{"id":"74b5e907e58e_54","__typename":"Paragraph","name":"b727","text":"Conversely, it turned out that using “standard” initialization brought about a much bigger gap in variance between weight gradients at the network’s lower layers, which were higher, and those at its top-most layers, which were approaching zero.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_55":{"id":"74b5e907e58e_55","__typename":"Paragraph","name":"6516","text":"Without Xavier init. Credit: Glorot & Bengio.","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*mDilNz4ADDbbr8Qb4d4RqQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":29,"end":44,"type":"A","href":"http:\u002F\u002Fproceedings.mlr.press\u002Fv9\u002Fglorot10a\u002Fglorot10a.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_56":{"id":"74b5e907e58e_56","__typename":"Paragraph","name":"fc04","text":"To drive the point home, Glorot and Bengio demonstrated that networks initialized with Xavier achieved substantially quicker convergence and higher accuracy on the CIFAR-10 image classification task.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":164,"end":198,"type":"A","href":"https:\u002F\u002Fwww.cs.toronto.edu\u002F~kriz\u002Fcifar.html","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_57":{"id":"74b5e907e58e_57","__typename":"Paragraph","name":"4c2a","text":"Let’s re-run our 100-layer tanh network once more, this time using Xavier initialization:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_58":{"id":"74b5e907e58e_58","__typename":"Paragraph","name":"92b1","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3NiBW8yi-gYrOpsy70PNEg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_59":{"id":"74b5e907e58e_59","__typename":"Paragraph","name":"92d5","text":"In our experimental network, Xavier initialization performs pretty identical to the home-grown method that we derived earlier, where we sampled values from a random normal distribution and scaled by the square root of number of incoming network connections, n.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":258,"end":259,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_60":{"id":"74b5e907e58e_60","__typename":"Paragraph","name":"9dba","text":"Kaiming Initialization","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_61":{"id":"74b5e907e58e_61","__typename":"Paragraph","name":"e8d9","text":"Conceptually, it makes sense that when using activation functions that are symmetric about zero and have outputs inside [-1,1], such as softsign and tanh, we’d want the activation outputs of each layer to have a mean of 0 and a standard deviation around 1, on average. This is precisely what our home-grown method and Xavier both enable.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_62":{"id":"74b5e907e58e_62","__typename":"Paragraph","name":"863f","text":"But what if we’re using ReLU activation functions? Would it still make sense to want to scale random initial weight values in the same way?","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_63":{"id":"74b5e907e58e_63","__typename":"Paragraph","name":"fd85","text":"ReLU activation function. Credit: Kanchan Sarkar’s blog.","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*njuH4XVXf-l9pR_RorUOrA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":51,"end":55,"type":"A","href":"https:\u002F\u002Fmedium.com\u002F@kanchansarkar\u002Frelu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_64":{"id":"74b5e907e58e_64","__typename":"Paragraph","name":"6233","text":"To see what would happen, let’s use a ReLU activation instead of tanh in one of our hypothetical network’s layers and observe the expected standard deviation of its outputs.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_65":{"id":"74b5e907e58e_65","__typename":"Paragraph","name":"e89e","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*0C5Beclgsv-_HEaOfV8eJA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_66":{"id":"74b5e907e58e_66","__typename":"Paragraph","name":"1765","text":"It turns out that when using a ReLU activation, a single layer will, on average have standard deviation that’s very close to the square root of the number of input connections, divided by the square root of two, or √512\u002F√2 in our example.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":177,"end":210,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_67":{"id":"74b5e907e58e_67","__typename":"Paragraph","name":"4a42","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*dZ5UcHx2RTeLXL46YxKgbw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_68":{"id":"74b5e907e58e_68","__typename":"Paragraph","name":"edc4","text":"Scaling the values of the weight matrix a by this number will cause each individual ReLU layer to have a standard deviation of 1 on average.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":40,"end":41,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_69":{"id":"74b5e907e58e_69","__typename":"Paragraph","name":"e1d6","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*1G5dke8TAGumS88OKa3TfA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_70":{"id":"74b5e907e58e_70","__typename":"Paragraph","name":"f1cf","text":"As we showed before, keeping the standard deviation of layers’ activations around 1 will allow us to stack several more layers in a deep neural network without gradients exploding or vanishing.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_71":{"id":"74b5e907e58e_71","__typename":"Paragraph","name":"3f29","text":"This exploration into how to best initialize weights in networks with ReLU-like activations is what motivated Kaiming He et. al. to propose their own initialization scheme that’s tailored for deep neural nets that use these kinds of asymmetric, non-linear activations.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":132,"end":171,"type":"A","href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1502.01852.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_72":{"id":"74b5e907e58e_72","__typename":"Paragraph","name":"f0db","text":"In their 2015 paper, He et. al. demonstrated that deep networks (e.g. a 22-layer CNN) would converge much earlier if the following input weight initialization strategy is employed:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_73":{"id":"74b5e907e58e_73","__typename":"Paragraph","name":"1f94","text":"Create a tensor with the dimensions appropriate for a weight matrix at a given layer, and populate it with numbers randomly chosen from a standard normal distribution.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_74":{"id":"74b5e907e58e_74","__typename":"Paragraph","name":"e8ea","text":"Multiply each randomly chosen number by √2\u002F√n where n is the number of incoming connections coming into a given layer from the previous layer’s output (also known as the “fan-in”).","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":40,"end":41,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":43,"end":45,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":52,"end":53,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_75":{"id":"74b5e907e58e_75","__typename":"Paragraph","name":"0e8d","text":"Bias tensors are initialized to zero.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_76":{"id":"74b5e907e58e_76","__typename":"Paragraph","name":"bc86","text":"We can follow these directions to implement our own version of Kaiming initialization and verify that it can indeed prevent activation outputs from exploding or vanishing if ReLU is used at all layers of our hypothetical 100-layer network.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_77":{"id":"74b5e907e58e_77","__typename":"Paragraph","name":"78a5","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*RD_c4ayThCkRvODAIMfOEQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_78":{"id":"74b5e907e58e_78","__typename":"Paragraph","name":"dbc9","text":"As a final comparison, here’s what would happen if we were to use Xavier initialization, instead.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_79":{"id":"74b5e907e58e_79","__typename":"Paragraph","name":"9770","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*_1RKMYJbwsIa4SYAj8ol-A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_80":{"id":"74b5e907e58e_80","__typename":"Paragraph","name":"ff7b","text":"Ouch! When using Xavier to initialize weights, activation outputs have almost completely vanished by the 100th layer!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_81":{"id":"74b5e907e58e_81","__typename":"Paragraph","name":"944b","text":"Incidentally, when they trained even deeper networks that used ReLUs, He et. al. found that a 30-layer CNN using Xavier initialization stalled completely and didn’t learn at all. However, when the same network was initialized according to the three-step procedure outlined above, it enjoyed substantially greater convergence.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_82":{"id":"74b5e907e58e_82","__typename":"Paragraph","name":"b853","text":"Convergence of a 30-layer CNN thanks to Kaiming init. Credit: He et. al.","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*AcZIzXFAJm_ZafRKleF_0g.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":62,"end":72,"type":"A","href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1502.01852.pdf","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":17,"end":25,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_83":{"id":"74b5e907e58e_83","__typename":"Paragraph","name":"049e","text":"The moral of the story for us is that any network we train from scratch, especially for computer vision applications, will almost certainly contain ReLU activation functions and be several layers deep. In such cases, Kaiming should be our go-to weight init strategy.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_84":{"id":"74b5e907e58e_84","__typename":"Paragraph","name":"e55f","text":"Yes, You Too Can Be a Researcher","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_85":{"id":"74b5e907e58e_85","__typename":"Paragraph","name":"343f","text":"Even more importantly, I’m not ashamed to admit that I felt intimidated when I saw the Xavier and Kaiming formulas for the first time. What with their respective square roots of six and two, part of me couldn’t help but feel like they must have been the result of some sort of oracular wisdom I couldn’t hope to fathom on my own. And let’s face it, sometimes the math in deep learning papers can look a lot like hieroglyphics, except with no Rosetta Stone to aid in translation.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":401,"end":425,"type":"A","href":"https:\u002F\u002Ftwitter.com\u002Fseluappendix","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":442,"end":455,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FRosetta_Stone","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:74b5e907e58e_86":{"id":"74b5e907e58e_86","__typename":"Paragraph","name":"4889","text":"But I think the journey we took here showed us that this knee-jerk response of feeling of intimidated, while wholly understandable, is by no means unavoidable. Although the Kaiming and (especially) the Xavier papers do contain their fair share of math, we saw firsthand how experiments, empirical observation, and some straightforward common sense were enough to help derive the core set of principals underpinning what is currently the most widely-used weight initialization scheme.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:74b5e907e58e_87":{"id":"74b5e907e58e_87","__typename":"Paragraph","name":"c773","text":"Alternately put: when in doubt, be courageous, try things out, and see what happens!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"ImageMetadata:1*ne6gE3vogzJp53lwAYxtGw.png":{"id":"1*ne6gE3vogzJp53lwAYxtGw.png","__typename":"ImageMetadata","originalHeight":90,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*IK15xc15E1LJGlDP1FEXFA.png":{"id":"1*IK15xc15E1LJGlDP1FEXFA.png","__typename":"ImageMetadata","originalHeight":270,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*_yr6lnXY-1aXVUWb1MJIYA.png":{"id":"1*_yr6lnXY-1aXVUWb1MJIYA.png","__typename":"ImageMetadata","originalHeight":398,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*z89-cC4jCGPOkp3cnbyr8A.png":{"id":"1*z89-cC4jCGPOkp3cnbyr8A.png","__typename":"ImageMetadata","originalHeight":360,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*K3AIFVUelCr0z646zrQjPw.png":{"id":"1*K3AIFVUelCr0z646zrQjPw.png","__typename":"ImageMetadata","originalHeight":212,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*oJDRa2HOPhe5JV7co5Ig-A.png":{"id":"1*oJDRa2HOPhe5JV7co5Ig-A.png","__typename":"ImageMetadata","originalHeight":616,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*wMTdWrSPOXh8C6XxoSO7pg.png":{"id":"1*wMTdWrSPOXh8C6XxoSO7pg.png","__typename":"ImageMetadata","originalHeight":444,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*qDpw22Z8XSDZe5MLLOLUew.png":{"id":"1*qDpw22Z8XSDZe5MLLOLUew.png","__typename":"ImageMetadata","originalHeight":618,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*5LAW2b1nDhPB9k7gt68yZg.png":{"id":"1*5LAW2b1nDhPB9k7gt68yZg.png","__typename":"ImageMetadata","originalHeight":444,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*8-f9bmfeVVWwLLqSoQADSA.png":{"id":"1*8-f9bmfeVVWwLLqSoQADSA.png","__typename":"ImageMetadata","originalHeight":360,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*39Dm-zzV98YO-WKCfXgeVg.png":{"id":"1*39Dm-zzV98YO-WKCfXgeVg.png","__typename":"ImageMetadata","originalHeight":264,"originalWidth":371,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*5Ko4_sp9-58wK_hFL2GCHQ.png":{"id":"1*5Ko4_sp9-58wK_hFL2GCHQ.png","__typename":"ImageMetadata","originalHeight":464,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*RJ2AxAObnSszBlJ6_LZKrQ.png":{"id":"1*RJ2AxAObnSszBlJ6_LZKrQ.png","__typename":"ImageMetadata","originalHeight":330,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*H6t3yYBLlinNRUwmL-d7vw.png":{"id":"1*H6t3yYBLlinNRUwmL-d7vw.png","__typename":"ImageMetadata","originalHeight":226,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*Gelf2ZcKYowsLf5FT4n0BQ.png":{"id":"1*Gelf2ZcKYowsLf5FT4n0BQ.png","__typename":"ImageMetadata","originalHeight":474,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*mDilNz4ADDbbr8Qb4d4RqQ.png":{"id":"1*mDilNz4ADDbbr8Qb4d4RqQ.png","__typename":"ImageMetadata","originalHeight":480,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*3NiBW8yi-gYrOpsy70PNEg.png":{"id":"1*3NiBW8yi-gYrOpsy70PNEg.png","__typename":"ImageMetadata","originalHeight":450,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*njuH4XVXf-l9pR_RorUOrA.png":{"id":"1*njuH4XVXf-l9pR_RorUOrA.png","__typename":"ImageMetadata","originalHeight":278,"originalWidth":357,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*0C5Beclgsv-_HEaOfV8eJA.png":{"id":"1*0C5Beclgsv-_HEaOfV8eJA.png","__typename":"ImageMetadata","originalHeight":552,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*dZ5UcHx2RTeLXL46YxKgbw.png":{"id":"1*dZ5UcHx2RTeLXL46YxKgbw.png","__typename":"ImageMetadata","originalHeight":146,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*1G5dke8TAGumS88OKa3TfA.png":{"id":"1*1G5dke8TAGumS88OKa3TfA.png","__typename":"ImageMetadata","originalHeight":446,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*RD_c4ayThCkRvODAIMfOEQ.png":{"id":"1*RD_c4ayThCkRvODAIMfOEQ.png","__typename":"ImageMetadata","originalHeight":506,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*_1RKMYJbwsIa4SYAj8ol-A.png":{"id":"1*_1RKMYJbwsIa4SYAj8ol-A.png","__typename":"ImageMetadata","originalHeight":366,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*AcZIzXFAJm_ZafRKleF_0g.png":{"id":"1*AcZIzXFAJm_ZafRKleF_0g.png","__typename":"ImageMetadata","originalHeight":810,"originalWidth":1400,"focusPercentX":null,"focusPercentY":null,"alt":null},"Tag:deep-learning":{"id":"deep-learning","__typename":"Tag","displayTitle":"Deep Learning"},"Tag:neural-networks":{"id":"neural-networks","__typename":"Tag","displayTitle":"Neural Networks"},"Tag:weight-initialization":{"id":"weight-initialization","__typename":"Tag","displayTitle":"Weight Initialization"},"Tag:towards-data-science":{"id":"towards-data-science","__typename":"Tag","displayTitle":"Towards Data Science"},"ImageMetadata:0*mk6Rc_ydMbO2RUZ9":{"id":"0*mk6Rc_ydMbO2RUZ9","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:7c4c3262f36e":{"id":"7c4c3262f36e","__typename":"User","name":"Luca Piccinelli","username":"luca-picci","bio":"I’m a programmer. I love programming, any language, any paradigm","isFollowing":null,"imageId":"1*N3QgrRNao03AH6juPIk5rA.jpeg","mediumMemberAt":1577533516361,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"luca-picci.medium.com"}},"hasSubdomain":true},"Post:c0072454d75c":{"id":"c0072454d75c","__typename":"Post","title":"Being a COBOL developer can be very fun","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fbeing-a-cobol-developer-can-be-very-fun-c0072454d75c","previewImage":{"__ref":"ImageMetadata:0*mk6Rc_ydMbO2RUZ9"},"isPublished":true,"firstPublishedAt":1613259169875,"readingTime":5.183962264150944,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:7c4c3262f36e"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*2J3iaDnuLhonNGvlTKthiQ.png":{"id":"1*2J3iaDnuLhonNGvlTKthiQ.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:22405c3b2875":{"id":"22405c3b2875","__typename":"User","name":"Maarten Grootendorst","username":"maartengrootendorst","bio":"Data Scientist | Psychologist. Passionate about anything AI-related! Get in touch: https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmgrootendorst\u002F","isFollowing":null,"imageId":"2*3w_iJjnOEHRJ6duKNQxIDQ.jpeg","mediumMemberAt":1563038015000,"customDomainState":null,"hasSubdomain":false},"Post:918109d069fa":{"id":"918109d069fa","__typename":"Post","title":"9 Distance Measures in Data Science","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002F9-distance-measures-in-data-science-918109d069fa","previewImage":{"__ref":"ImageMetadata:1*2J3iaDnuLhonNGvlTKthiQ.png"},"isPublished":true,"firstPublishedAt":1612184403563,"readingTime":9.831132075471698,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:22405c3b2875"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*Sj76gx1iy30Kq2mTEIL-jg.jpeg":{"id":"1*Sj76gx1iy30Kq2mTEIL-jg.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:976684b56e2c":{"id":"976684b56e2c","__typename":"User","name":"Pooja Rane","username":"pooja-rane1194","bio":"20 Something. 5 Feet Tall Human trying to understand the world. Volunteer Teacher at a Non Profit. A firm believer in Education","isFollowing":null,"imageId":"1*8hTMsc1pCNlvk4RQIcVwLg@2x.jpeg","mediumMemberAt":1610553076000,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"pooja-rane1194.medium.com"}},"hasSubdomain":true},"Post:54f1bdd6dfaa":{"id":"54f1bdd6dfaa","__typename":"Post","title":"Excel vs Python: How to do Common Data Analysis Tasks","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fexcel-vs-python-how-to-do-common-data-analysis-tasks-54f1bdd6dfaa","previewImage":{"__ref":"ImageMetadata:1*Sj76gx1iy30Kq2mTEIL-jg.jpeg"},"isPublished":true,"firstPublishedAt":1613364622859,"readingTime":6.728301886792453,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:976684b56e2c"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*LXEzOG6snVtCtYszzg8N4g.jpeg":{"id":"1*LXEzOG6snVtCtYszzg8N4g.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:d2f73a5f47df":{"id":"d2f73a5f47df","__typename":"User","name":"Silvia Zeamer","username":"szeamer","bio":"Senior at Wellesley College studying Media Arts and Sciences. Future research scientist in HCI and security. Here for human connection \u003C3","isFollowing":null,"imageId":"1*eedSYFTbvtDES1sULxxvIQ.jpeg","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"szeamer.medium.com"}},"hasSubdomain":true},"Post:7a0a798adc13":{"id":"7a0a798adc13","__typename":"Post","title":"How to Extract the Text from PDFs Using Python and the Google Cloud Vision API","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-to-extract-the-text-from-pdfs-using-python-and-the-google-cloud-vision-api-7a0a798adc13","previewImage":{"__ref":"ImageMetadata:1*LXEzOG6snVtCtYszzg8N4g.jpeg"},"isPublished":true,"firstPublishedAt":1613262453116,"readingTime":9.08867924528302,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:d2f73a5f47df"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*ymxq_lqn1KFWwhbzsT4k8w.png":{"id":"1*ymxq_lqn1KFWwhbzsT4k8w.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:57f13c0ea39a":{"id":"57f13c0ea39a","__typename":"User","name":"Tomaz Bratanic","username":"bratanic-tomaz","bio":"Data explorer. Turn everything into a graph.","isFollowing":null,"imageId":"1*SnWQP0l4Vg9577WAErbjfw.jpeg","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"bratanic-tomaz.medium.com"}},"hasSubdomain":true},"Post:b65e7e30273e":{"id":"b65e7e30273e","__typename":"Post","title":"From text to knowledge. The information extraction pipeline","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Ffrom-text-to-knowledge-the-information-extraction-pipeline-b65e7e30273e","previewImage":{"__ref":"ImageMetadata:1*ymxq_lqn1KFWwhbzsT4k8w.png"},"isPublished":true,"firstPublishedAt":1613136760825,"readingTime":10.541509433962263,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:57f13c0ea39a"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*iI5iT11GfqXGa1j7hcPOPA.jpeg":{"id":"1*iI5iT11GfqXGa1j7hcPOPA.jpeg","__typename":"ImageMetadata","focusPercentX":47,"focusPercentY":50},"User:6f2e62f8c32f":{"id":"6f2e62f8c32f","__typename":"User","name":"Ahmad Abdullah","username":"ahmad-abdullah","bio":"I observe and put my thoughts into words. Machine learning enthusiast. Currently pursuing MS Data Science.","isFollowing":null,"imageId":"1*OBqWgNO6IjEc67APqAGkQA.png","mediumMemberAt":1612724263000,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"ahmad-abdullah.medium.com"}},"hasSubdomain":true},"Post:54f6aedc1c46":{"id":"54f6aedc1c46","__typename":"Post","title":"18 Git Commands I Learned During My First Year as a Software Developer","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fgit-commands-cheat-sheet-software-developer-54f6aedc1c46","previewImage":{"__ref":"ImageMetadata:1*iI5iT11GfqXGa1j7hcPOPA.jpeg"},"isPublished":true,"firstPublishedAt":1612489263716,"readingTime":9.485849056603774,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:6f2e62f8c32f"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*kyCODwc_4YLbm7mS":{"id":"0*kyCODwc_4YLbm7mS","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:b1f214c06d3e":{"id":"b1f214c06d3e","__typename":"User","name":"Mostafa Ibrahim","username":"mostafaosama18","bio":"Programmer. University College London Computer Science Graduate. ARM Full Stack Web Dev. Passionate about Machine Learning in Healthcare.","isFollowing":null,"imageId":"1*8uYq8Y0kcln3-7KZZG6JZg.jpeg","mediumMemberAt":1599395747000,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"mostafaosama18.medium.com"}},"hasSubdomain":true},"Post:75c0b3f37312":{"id":"75c0b3f37312","__typename":"Post","title":"Deepmind releases a new State-Of-The-Art Image Classification model — NFNets","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fdeepmind-releases-a-new-state-of-the-art-image-classification-model-nfnets-75c0b3f37312","previewImage":{"__ref":"ImageMetadata:0*kyCODwc_4YLbm7mS"},"isPublished":true,"firstPublishedAt":1613229954012,"readingTime":5.538050314465409,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:b1f214c06d3e"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*0DxkIBPiL3Kckzrc":{"id":"0*0DxkIBPiL3Kckzrc","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:7938431b336a":{"id":"7938431b336a","__typename":"User","name":"Sara A. Metwalli","username":"saraametwalli","bio":"Ph.D. student working on Quantum Computing. Traveler, writing lover, science enthusiast, and CS instructor. Get in touch with me bit.ly\u002F2CvFAw6","isFollowing":null,"imageId":"1*BY6sCRisdVuk5GyPL_q7rw.jpeg","mediumMemberAt":1575015661000,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"saraametwalli.medium.com"}},"hasSubdomain":true},"Post:3ad111134771":{"id":"3ad111134771","__typename":"Post","title":"5 Data Science Programming Languages Not Including Python or R","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002F5-data-science-programming-languages-not-including-python-or-r-3ad111134771","previewImage":{"__ref":"ImageMetadata:0*0DxkIBPiL3Kckzrc"},"isPublished":true,"firstPublishedAt":1613190702936,"readingTime":5.113207547169812,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:7938431b336a"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"Post:954fb9b47c79":{"id":"954fb9b47c79","__typename":"Post","canonicalUrl":"","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","isCacheableContent":false,"bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:74b5e907e58e_0"},{"__ref":"Paragraph:74b5e907e58e_1"},{"__ref":"Paragraph:74b5e907e58e_2"},{"__ref":"Paragraph:74b5e907e58e_3"},{"__ref":"Paragraph:74b5e907e58e_4"},{"__ref":"Paragraph:74b5e907e58e_5"},{"__ref":"Paragraph:74b5e907e58e_6"},{"__ref":"Paragraph:74b5e907e58e_7"},{"__ref":"Paragraph:74b5e907e58e_8"},{"__ref":"Paragraph:74b5e907e58e_9"},{"__ref":"Paragraph:74b5e907e58e_10"},{"__ref":"Paragraph:74b5e907e58e_11"},{"__ref":"Paragraph:74b5e907e58e_12"},{"__ref":"Paragraph:74b5e907e58e_13"},{"__ref":"Paragraph:74b5e907e58e_14"},{"__ref":"Paragraph:74b5e907e58e_15"},{"__ref":"Paragraph:74b5e907e58e_16"},{"__ref":"Paragraph:74b5e907e58e_17"},{"__ref":"Paragraph:74b5e907e58e_18"},{"__ref":"Paragraph:74b5e907e58e_19"},{"__ref":"Paragraph:74b5e907e58e_20"},{"__ref":"Paragraph:74b5e907e58e_21"},{"__ref":"Paragraph:74b5e907e58e_22"},{"__ref":"Paragraph:74b5e907e58e_23"},{"__ref":"Paragraph:74b5e907e58e_24"},{"__ref":"Paragraph:74b5e907e58e_25"},{"__ref":"Paragraph:74b5e907e58e_26"},{"__ref":"Paragraph:74b5e907e58e_27"},{"__ref":"Paragraph:74b5e907e58e_28"},{"__ref":"Paragraph:74b5e907e58e_29"},{"__ref":"Paragraph:74b5e907e58e_30"},{"__ref":"Paragraph:74b5e907e58e_31"},{"__ref":"Paragraph:74b5e907e58e_32"},{"__ref":"Paragraph:74b5e907e58e_33"},{"__ref":"Paragraph:74b5e907e58e_34"},{"__ref":"Paragraph:74b5e907e58e_35"},{"__ref":"Paragraph:74b5e907e58e_36"},{"__ref":"Paragraph:74b5e907e58e_37"},{"__ref":"Paragraph:74b5e907e58e_38"},{"__ref":"Paragraph:74b5e907e58e_39"},{"__ref":"Paragraph:74b5e907e58e_40"},{"__ref":"Paragraph:74b5e907e58e_41"},{"__ref":"Paragraph:74b5e907e58e_42"},{"__ref":"Paragraph:74b5e907e58e_43"},{"__ref":"Paragraph:74b5e907e58e_44"},{"__ref":"Paragraph:74b5e907e58e_45"},{"__ref":"Paragraph:74b5e907e58e_46"},{"__ref":"Paragraph:74b5e907e58e_47"},{"__ref":"Paragraph:74b5e907e58e_48"},{"__ref":"Paragraph:74b5e907e58e_49"},{"__ref":"Paragraph:74b5e907e58e_50"},{"__ref":"Paragraph:74b5e907e58e_51"},{"__ref":"Paragraph:74b5e907e58e_52"},{"__ref":"Paragraph:74b5e907e58e_53"},{"__ref":"Paragraph:74b5e907e58e_54"},{"__ref":"Paragraph:74b5e907e58e_55"},{"__ref":"Paragraph:74b5e907e58e_56"},{"__ref":"Paragraph:74b5e907e58e_57"},{"__ref":"Paragraph:74b5e907e58e_58"},{"__ref":"Paragraph:74b5e907e58e_59"},{"__ref":"Paragraph:74b5e907e58e_60"},{"__ref":"Paragraph:74b5e907e58e_61"},{"__ref":"Paragraph:74b5e907e58e_62"},{"__ref":"Paragraph:74b5e907e58e_63"},{"__ref":"Paragraph:74b5e907e58e_64"},{"__ref":"Paragraph:74b5e907e58e_65"},{"__ref":"Paragraph:74b5e907e58e_66"},{"__ref":"Paragraph:74b5e907e58e_67"},{"__ref":"Paragraph:74b5e907e58e_68"},{"__ref":"Paragraph:74b5e907e58e_69"},{"__ref":"Paragraph:74b5e907e58e_70"},{"__ref":"Paragraph:74b5e907e58e_71"},{"__ref":"Paragraph:74b5e907e58e_72"},{"__ref":"Paragraph:74b5e907e58e_73"},{"__ref":"Paragraph:74b5e907e58e_74"},{"__ref":"Paragraph:74b5e907e58e_75"},{"__ref":"Paragraph:74b5e907e58e_76"},{"__ref":"Paragraph:74b5e907e58e_77"},{"__ref":"Paragraph:74b5e907e58e_78"},{"__ref":"Paragraph:74b5e907e58e_79"},{"__ref":"Paragraph:74b5e907e58e_80"},{"__ref":"Paragraph:74b5e907e58e_81"},{"__ref":"Paragraph:74b5e907e58e_82"},{"__ref":"Paragraph:74b5e907e58e_83"},{"__ref":"Paragraph:74b5e907e58e_84"},{"__ref":"Paragraph:74b5e907e58e_85"},{"__ref":"Paragraph:74b5e907e58e_86"},{"__ref":"Paragraph:74b5e907e58e_87"}],"sections":[{"__typename":"Section","name":"4e73","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"creator":{"__ref":"User:97c4870a6508"},"customStyleSheet":{"__ref":"CustomStyleSheet:7d00fb9fecc6"},"firstPublishedAt":1554281025838,"isLocked":false,"isPublished":true,"isShortform":false,"layerCake":3,"primaryTopic":{"__ref":"Topic:1eca0103fff3"},"title":"Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming","readCreatorPostsCount":0,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fweight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79","isLimitedState":false,"visibility":"PUBLIC","license":"ALL_RIGHTS_RESERVED","allowResponses":true,"newsletterId":"","sequence":null,"tags":[{"__ref":"Tag:deep-learning"},{"__ref":"Tag:neural-networks"},{"__ref":"Tag:weight-initialization"},{"__ref":"Tag:towards-data-science"}],"topics":[{"__typename":"Topic","topicId":"1eca0103fff3","name":"Machine Learning"}],"viewerClapCount":0,"showSubscribeToProfilePromo":false,"showSubscribeToCollectionNewsletterV3Promo":true,"inResponseToPostResult":null,"isNewsletter":false,"socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1554397717064,"readingTime":10.814150943396225,"previewContent":{"__typename":"PreviewContent","subtitle":"Exploring the evolution of initializing layer weights in neural networks: from old-school to Xavier, and arriving finally at Kaiming init."},"previewImage":{"__ref":"ImageMetadata:1*AcZIzXFAJm_ZafRKleF_0g.png"},"creatorPartnerProgramEnrollmentStatus":"PERMISSION_DENIED","clapCount":3580,"lockedSource":"LOCKED_POST_SOURCE_NONE","isSuspended":false,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"pinnedByCreatorAt":0,"curationEligibleAt":0,"responseDistribution":"NOT_DISTRIBUTED","shareKey":null,"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:c0072454d75c"},{"__ref":"Post:918109d069fa"},{"__ref":"Post:54f1bdd6dfaa"},{"__ref":"Post:7a0a798adc13"},{"__ref":"Post:b65e7e30273e"},{"__ref":"Post:54f6aedc1c46"},{"__ref":"Post:75c0b3f37312"},{"__ref":"Post:3ad111134771"}]},"collaborators":[],"translationSourcePost":null,"inResponseToMediaResource":null,"isDistributionAlertDismissed":false,"audioVersionUrl":"","seoTitle":"","updatedAt":1554397717166,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","postResponses":{"__typename":"PostResponses","count":23},"latestPublishedVersion":"74b5e907e58e","isPublishToEmail":false,"readingList":"READING_LIST_NONE","voterCount":912,"recommenders":[]}}</script><script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/manifest.js"></script><script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/8247.js"></script><script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/main.js"></script><script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/5573.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/instrumentation.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/reporting.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1752.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/4464.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/8342.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1148.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/9692.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/5064.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/9274.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/2846.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/7012.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/7993.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/9972.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/5127.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/9106.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/8751.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/9458.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/7131.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/8127.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/463.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/1373.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/587.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/2514.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/3874.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/857.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/8286.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/5429.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/8831.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/2450.js"></script>
<script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/Post.js"></script><script>window.main();</script><script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/p.js" async="" id="parsely-cf"></script><script src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/api.js" async=""></script><div><div class="fc fe ms wv v ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm xn tb xo xp xq xr tc xs xt xu xv td xw xx"><div><div class="branch-journeys-top"><div class="n ck"><p class="ba b bb bc hd">To make Medium work, we log user data. By using Medium, you agree to our <a href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9" class="ei ej bz ca cb cc cd ce cf bl cg em en iy" target="_blank" rel="noopener">Privacy Policy</a>, including cookie policy.</p><div class="xy s xz"><div class="cf s am fd"><button class="ei ej bz ca cb cc cd ce cf bl ek el cg em en" data-testid="close-button" aria-label="close"><svg width="19" height="19" viewBox="0 0 19 19" class="hx"><path d="M13.8 4.6L9.5 8.89 5.21 4.6l-.61.61 4.29 4.3-4.29 4.28.61.62 4.3-4.3 4.28 4.3.62-.62-4.3-4.29 4.3-4.29" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div><iframe src="Weight%20Initialization%20in%20Neural%20Networks%20A%20Journey%20From%20the%20Basics%20to%20Kaiming%20|%20by%20James%20Dellinger%20|%20Towards%20Data%20Science_files/a16180790160.html" tabindex="-1" title="Optimizely Internal Frame" style="display: none;" width="0" hidden="" height="0"></iframe></body></html>